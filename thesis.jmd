---
title : Dynamic Optimisation using the Julia Programming Language
author : Nathan Davey
options :
    template : julia_tex.tpl
---

```julia; echo=false; results="hidden"
using Images, Plots, Colors, Polynomials, BenchmarkTools, ForwardDiff, Reduce, Intervals
using MorePolynomials;
plotly()

struct Begin
    text
end

struct End
    text
end

Base.show(io::IO, m::MIME"text/latex", b::Begin) = write(io, "\\begin{$(b.text)}\n ")
Base.show(io::IO, m::MIME"text/latex", e::End) = write(io, "\\end{$(e.text)}\n")

struct Newpage end
Base.show(io::IO, m::MIME"text/latex", n::Newpage) = write(io, "\\newpage\n ")

struct Ack end
Base.show(io::IO, m::MIME"text/latex", a::Ack) = write(io, "\\section*{Acknowledgement}")

struct BeginAppendix end
Base.show(io::IO, m::MIME"text/latex", a::BeginAppendix) = write(io, "\\begin{appendices}\n ")

struct EndAppendix end
Base.show(io::IO, m::MIME"text/latex", a::EndAppendix) = write(io, "\\end{appendices}\n ")

struct Bib end
Base.show(io::IO, m::MIME"text/latex", b::Bib) = write(io, "\\bibliography{references}\n\\bibliographystyle{vancouver}\n ")

struct NomItem
    symbol
    text
end
Base.show(io::IO, m::MIME"text/latex", n::NomItem) = write(io, "\\nomenclature{\$ $(n.symbol) \$}{$(n.text)}\n ")

struct NomPrint end
Base.show(io::IO, m::MIME"text/latex", n::NomPrint) = write(io, "\\printnomenclature\n ")

struct ContentsPrint end
Base.show(io::IO, m::MIME"text/latex", c::ContentsPrint) = write(io, "\\tableofcontents\n ")

struct BeginFig end

struct EndFig
    cap
    label
end
Base.show(io::IO, m::MIME"text/latex", b::BeginFig) = write(io, "\\begin{figure}[H]\n\\centering\n ")
Base.show(io::IO, m::MIME"text/latex", e::EndFig) = write(io, "\\caption{$(e.cap)}\\label{$(e.label)}\n\\end{figure}\n")

struct Label
    text
end
Base.show(io::IO, m::MIME"text/latex", l::Label) = write(io, "\\label{$(l.text)}\n")


struct Table
    cap
    label
    tableArray::Array
end

function Base.show(io::IO, m::MIME"text/latex", t::Table) 
    
    write(io, "\\begin{table}[h]\\label{$(t.label)}\\centering\n")
    ls = "l"
    r = size(t.tableArray)[1]
    c = size(t.tableArray)[2]
    for i = 1:c-1
        ls = ls*"l"
    end
    write(io, "\\begin{tabular}{$ls}\n")
    for i = 1:r
    out = ""
        for j = 1:c
            if j == c
               out = out * string(t.tableArray[i,j])* "\\\\" 
            else
               out = out * string(t.tableArray[i,j])* "&" 
            end
        end
        if i==1
            out = out * " \\hline  \n"
        else
            out = out * "\n"
        end
    write(io, out)
    end
    write(io, "\\end{tabular}\\caption{$(t.cap)}\n")
    write(io, "\\end{table}\n")
end



struct BeginColBox end
Base.show(io::IO, m::MIME"text/latex", b::BeginColBox) = write(io, "\\begin{tcolorbox}")
struct EndColBox end
Base.show(io::IO, m::MIME"text/latex", b::EndColBox) = write(io, "\\end{tcolorbox}")

``` 
! Begin("abstract")
The field of dynamic optimisation solvers is one dominated by programs of high complexity, both in implementation and user interface.
Moreover, within the field of dynamic optimisation methods involving so-called orthogonal collocation (or pseudospectral methods) have proven to achieve high accuracy with relatively few discretisation points ``\cite{Huntington2001AdvancementProblems}``.
They are well renown in the field of aerospace, with uses ranging from calculating the optimal path for space shuttle reentry to maximising payload delivered to orbit for vertical takeoff vertical landing spacecraft.
In addition, more recently a numerically focused programming language by the name of Julia has gained popularity due to its lightning speed (as fast as C) and its employment of features usually found in high level languages such as dynamic typing.
The aim of this work is to provide a background to dynamic optimisation using polynomial approximating functions in Julia, and outline steps for developing the next generation of intuitive dynamic optimisation solvers.
Along the way we will implement some examples and explore some of the ready to use packages developed for this purpose.
! End("abstract")
! Newpage()

! Ack()
> "The fear of the LORD is the beginning of wisdom: and the knowledge of the holy is understanding."
> Proverbs 9:10

I include the above quote because it addresses something which has been on my mind for some time during my studies.
Specifically the notion why we do what we do?
What is the point of all this study?
Furthermore what is the point of anything at all?
One might suggest we do these things because we enjoy them, which is a reasonable until you stop enjoying them, which happens with any activity after some time.
And yet we often keep doing them regardless, I guess in the hope that we start enjoying them again.
Much ink has been spilt over such thoughts, and more so with the rise of existentialism, and as such my aim is not to give the answer, but ask the question.
We're told to keep trying, to never give up until we reach the top, but do we ever stop to ask why we must get to the top in the first place?
Sometimes it's best to be thankful for what we have.
Not to try and get to the top in a worldly sense, but to enjoy what I believe God has given us no matter how small.

I would like to thank the staff and students of Imperial College London for support and good company they have offered over the years.
I would like to thank my supervisor Dr Eric Kerrigan for being patient with my sometimes lacking understanding, and for providing truly constructive feedback.
I would like to thank Yuanbo Nie for always offering a helping hand, and for his speedy replies to all my questions.
I would like to thank my personal tutor Dr Koon-Yang Lee for being a good friend over the years.
I would like to thank my housemates, my parents, and the good folks at the Christian Union for being a support for me when I needed them.
And finally I would like to thank my God and His son for His guiding hand over the years.

To go back to the quote, it's from one of the books in the Bible referred to as the wisdom literature.
Proverbs mostly contains sayings about how to do good in order to live rightly before God.
But here lies the wisdom, at least for me, in this quote. 
That to know heavenly things is the beginning of the lower ones.
To fear the Lord leads to great wisdom.
Because we must know why we study before we study.
We must know that our efforts are for a greater purpose, if we are to make any lasting effort.
Because to know that we know anything at all we have to start somewhere.
And that for all the wisdom and knowledge that this world contains, the best of us are those who use it to do good.
And though fear of the Lord this is what my experiences have taught me, that the best of us are those who serve others above themselves.
My motivation is to be more like them.
For to do this is more than wisdom or knowledge, it is pure love.

! Newpage()

! ContentsPrint()

! Newpage()

! NomItem("J","Objective function")
! NomItem("\\pmb{g}","NLP Constraint functions")
! NomItem("\\pmb{f}","Vector of all system dynamics functions")
! NomItem("f_i","i'th state system dynamics function")
! NomItem("x^{(i)}","i'th continuous state variable")
! NomItem("x_i","i'th state vector of state interpolating data points")
! NomItem("x_{ij}","i'th state j'th decision variable / interpolating point state value")
! NomItem("\\bar{x}_{ij}","i'th state j'th interpolating data point state time pair")
! NomItem("\\pmb{x}","Vector of state interpolating polynomials")
! NomItem("\\pmb{x}_i","i'th state interpolating polynomial")
! NomItem("\\tilde{x}_i","i'th state interpolation function")
! NomItem("u^{(i)}","i'th continuous control variable")
! NomItem("u_i","i'th control vector of control interpolating data points")
! NomItem("u_{ij}","i'th control j'th decision variable / interpolating point control value")
! NomItem("\\bar{u}_{ij}","i'th control j'th interpolating data point control time pair")
! NomItem("\\pmb{u}","Vector of control interpolating polynomials")
! NomItem("\\pmb{u}_i","i'th control interpolating polynomial")
! NomItem("\\tilde{u}_i","i'th control interpolation function")
! NomItem("\\pmb{b}","Vector of all boundary constraint functions")
! NomItem("\\pmb{h}","Vector of all path constraint functions")
! NomItem("t","Any time")
! NomItem("t_k","Time at collocation point k")
! NomItem("t_1","Start time")
! NomItem("t_F","End time")
! NomItem("t_{ij}","i'th state or control time at interpolating data point j ")
! NomItem("h_k","timestep")
! NomItem("\\tau_i","i'th state vector of collocation point times for dynamics function")
! NomItem("\\pmb{\\tau}","All collocation vectors for dynamics function")
! NomItem("\\tau^{(\\rho)}","Vector of collocation point times for objective function")
! NomItem("\\pmb{\\tau}^{(h)}","All vectors of collocation point times for path constraints")
! NomItem("k","Location of a collocation point")
! NomItem("n","Number of states")
! NomItem("c","Number of controls")
! NomItem("m","Number of mesh/collocation/interpolation points")
! NomItem("i","State or control index")
! NomItem("j","Iterative variable")
! NomItem("\\rho","Lagrange term for objective function")
! NomItem("\\tilde{\\rho}","Interpolated Lagrange term for objective function")
! NomItem("\\Phi","Mayer term for objective function")
! NomItem("L","Lagrange interpolating polynomial")
! NomItem("l","Intermediate Lagrange weights")
! NomItem("w","Lagrange barycentric weights")
! NomItem("w_{LGR}","Legendre-Gauss-Radau integration weights")
! NomItem("s","Slack variable")
! NomItem("y","Function output data points for Lagrange polynomials")
! NomItem("D","Differentiation matrix")
! NomItem("P_N","Legendre polynomials")


! NomPrint()

! Newpage()

# Introduction

## Motivation

### Dynamic optimisation
Optimisation problems are the focus of wide range of research fields, and have broad applications to almost any discipline.
As such, effective tools for solving optimal problems are extremely desirable, and are employed in fields such as medicine, robotics and aerospace.
Specifically, optimal problem solvers allow us to streamline the design an operation of, for example, a reusable spacecraft, or a walking robot, or the layout of a hospital.
If the problem has a cost function and can be formulated subject to certain mathematical constraints, it can be optimised.

Dynamic optimisation is a subset of general optimisation problems, where the problem is best thought of as finding the optimal control input that minimises some cost function through statespace subject to system dynamics and constraints. 
An example would be finding the optimal thrust output over time from the earth to another body which maximises the final orbital radius (as seen in ``\cite{ICLOCS2:Raising}``). 

Dynamic optimisation problems can be solved by the process of transcription.
Transcription is the process of translating a continuous control problem into a discrete nonlinear programming problem (NLP) which can then be solved by an NLP solver.
A general formulation of the dynamic optimisation problem can be found in section ``\ref{dynamicsmath}``.


The focus of this project is thus to lay the foundations for a simple but powerful dynamic optimisation toolbox, such that users can spend more time on the problem formulation and results without needing a detailed background in optimisation.
As history has shown, more can be achieved when time is spent letting the tools work on the problem rather than trying to make the problem work with the tools.

### Imperial College London Optimal Control Software (ICLOCS)
ICLOCS is the MATLAB predecessor to the package we are attempting to lay the foundations for here.
It implements a number of collocation, mesh refinement and differentiation methods, and provides interfaces to a number solvers.
Three areas for improvement stand out with the current implementation of ICLOCS; the user interface, the ability to maintain an ever growing codebase, and the internal representation of states and controls.
With regards to the user interface, the user is often required to construct the problem over a number of files, and the user must often formulate the problem in a particular manner to be compatible with the ICLOCS functions.
With regards to the state of the codebase, ICLOCS suffers from feature creep, and the ability to implement new features often requires substantial wrangling with the code. 
With regards to the internal representation of states and controls, from the outset it was assumed that the dimensions of the state and control vectors would always be consistent.
This assumes a fixed number of collocation points for all states and controls for a given problem.
One of the goals of this text is to outline the foundations for a method which allows for a varying number of collocation points for each state and control using interpolating functions.


### Julia
The Julia programming language is a product of the desire to have highly performant code in a dynamic, high level format i.e. having your cake and eating it.
Julia has been designed with numerical analysis and computational science in mind ``\cite{Bezanson2014Julia:Computingb}``, and aims to solve what is referred to as the two language problem.
The two language problem is that, with the advent of rapid prototyping languages such as python and MATLAB, code can be written and tested quickly at the cost of scalability.
Once the code has been written, core components are translated into a low level but performant languages, e.g. C/C++ or Rust.
Julia bridges the gap by having easy to read and prototype code which is performant and even garbage collected.
This is achieved by a well thought out architecture and a clever just-in-time (JIT) compiler ``\cite{Bezanson2014Julia:Computingb}``.
While code must still be written with a certain level of awareness of lower level processes and implementations, and as such a certain style of programming must be adopted to achieve truly performant code, the main goals of Julia are delivered on to a more than satisfactory level.
The gains from Julia by solving this problem is more than just faster transition to production.
The ability to have performant, high level code can increase the shareability and modularity of code. 
For programs written natively in Julia, (providing the source code is easily accessible), users wishing to understand and adapt code packages no longer have to trace through difficult to understand C++ programs and try and guess which parts of code exist purely to speed up performance.

Although Julia takes heavy inspiration from other languages such as C, MATLAB. Python and Lisp (to name a few), through the implementations of its main paradigm it holds its own in the world of dynamic general programming languages.
By choosing to diverge from the commonly practiced object oriented programming (OOP) paradigm, Julia presents an alternative and more intuitive interface using multiple dispatch and strong type interfaces.
By types we refer to the data type of variables such as `Int`, `Float64` etc., but Julia also provides the ability to define types which contain other types (like structs in C), and abstract types from which other types can be subtyped.
We can execute different subroutines depending on the combination of the types of the arguments of a function, and this ability is referred to as multiple dispatch.
For example, the function `f(x::Int, y::Float64)` is a different function to `f(x::Int,y::Char)` or even `f(x::Float64, y::Int)`, but all three use the same `f` identifier i.e. we overload `f` for each type combination.

What is very apparent in Julia is that every line of code has been scrutinised, and each feature thought about to great depth.
The effect of this is that code feels like it makes sense, rather than a group of features bundled together into a programming language (see: PHP).
In addition, Julia is a general purpose language.
So general purpose that this very document has been typeset using Julia.
The advantage of this is the ability to apply Julia variety of applications.
If all the user wishes to do is simulate a spacecraft in orbit (for example), this benefit is of little consequence.
But say the user now wants a live visualisation of the spacecraft.
If there already exists a general purpose visualisation package in Julia, hours can be saved from having to develop an interface between your code and the outside world.




# Mathematical Background
## Dynamic optimisation problem formulation
! Label("dynamicsmath")
Here we will outline the basic formulation of the dynamic optimisation problem.
It is important to note that the main objective of dynamic optimisation is to find a set of optimal control inputs which results in the boundary constraints and system dynamics being satisfied, and a minimisation of the objective function.
As such, we can break down the problem into 3 main components:

```julia; echo=false; results="hidden"
problemComponents = ["System dynamics",
                     "Boundary and path constraints",
                     "Objective function"];
```

1) `j print(problemComponents[1])`
2) `j print(problemComponents[2])`
3) `j print(problemComponents[3])`
<!-- Illustrate this with a flow chart -->
The following discussion assumes the direct method i.e. transcription.
Transcription is the process of converting a continuous dynamic optimisation problem into an array of discrete constraints (which ensure system dynamics are consistent with the state as explained in section ``\ref{sysDyn}``) which can be solved by a nonlinear programming (NLP) solver.
The direct methods are, well, direct, because we just try and solve the problem by breaking it up into smaller constraint equations.
Indirect methods, on the other hand, solve the problem by reformulating (analytically) the problem using a set of first-order necessary conditions for optimality, which can then be solved.
Direct methods are currently of more interest as these conditions are often difficult to formulate, and indirect methods are more sensitive to the accuracy of the initial state guess ``\cite{Huntington2001AdvancementProblems}``.
Before we explore the direct method however, it may be beneficial to define what our dynamic optimisation problem will eventually become, a nonlinear programming problem.

### Nonlinear programming problem
If we can reformulate our dynamic problem into an NLP problem, we can use a number of widely available solvers to find optimal solutions.
The general formulation of the NLP problem is (as given by Ipopt from COIN-OR ``\cite{Ipopt:Documentation}``, a popular NLP solver)

$$
\begin{align}
\min_{x\in\mathbb{R}^n} & \quad J(\pmb{x}) \label{objectiveFunc} \\
\text{s.t.} & \quad \pmb{g}_L \leq \pmb{g}(\pmb{x}) \leq \pmb{g}_U \label{gineq}\\
& \quad \pmb{x}_L \leq \pmb{x} \leq \pmb{x}_U \label{xineq}
\end{align}
$$

Where
$$
J : \mathbb{R}^n \rightarrow \mathbb{R},
$$

is the objective function to be minimised,
$$
\pmb{x} \in \mathbb{R}^n
$$
is an array of decision variables and

$$
g : \mathbb{R}^n \rightarrow \mathbb{R}^m,
$$

are functions that represent nonlinear constraints.
In this text we use bold font to denote the existence of an array of either variables or functions.
In this particular case, ``\pmb{g}`` comprises of multiple constraint functions with multiple inputs and outputs.

The nonlinear constraint may also take the form (which is more common in the syntactic formulation of dynamic optimisation problems)
$$
\begin{equation}
\label{gfunc}
\pmb{g}(\pmb{x}) \leq 0
\end{equation}
$$
Solvers such as Ipopt additionally replace nonlinear inequality constrains with an equality constraint and a slack variable ``\cite{WachterShortMinutes}`` such that equation ``\ref{gineq}`` becomes ``\pmb{g}(\pmb{x}) - s = 0`` and ``\pmb{g}^L \leq s \leq \pmb{g}^U``. 
As such it makes sense to also include in our formulation the additional equality constriants
$$
\begin{equation}
\label{gfunceq}
\pmb{g}(\pmb{x}) = 0
\end{equation}
$$

The nonlinear constraints may take the form of either equation ``\ref{gfunc}`` or ``\ref{gfunceq}``, or both.

The target of dynamic optimisation is to discretise the dynamic optimisation problem into a set of constrained points (known as collocation points) which can be expressed as a series of dynamics constraints and solved as a nonlinear problem.
The forces that govern the system thus become a discretised set of equality constraints that essentially say the system must behave in this way otherwise the physics would be violated.
Another way to put it is rather than giving an input and calculating what the output would be based on extrapolation of the system dynamics through time marching (such as in a shooting method), we evaluate what the physics would have to be at each location in time to satisfy a given input.
<!-- Illustrate this with some diagrams -->

We will now go on to explore how the dynamics optimisation problem becomes the NLP problem.

### `j print(problemComponents[1])`
! Label("sysDyn")

The system dynamics are of key importance in the dynamic optimisation problem, and are what essentially separate it from a standard NLP problem.
By system dynamics, we are referring to the governing equations which describe the evolution of the state over time.
Simply put, if ``x`` is our state, ``u`` is our control input and ``t`` represents time we have

$$
\begin{equation}
\label{nakeddynamics}
\frac{\partial x}{\partial t}\rvert_{t_k} = \dot{x}\rvert_{t_k} = f(x,u)\rvert_{t_k}
\end{equation}
$$

Essentially we are saying the change of state through time (derivative) is a function of both the state(s) and control(s) at that instance in time. 

Let's define our terms a little more thoroughly.
Our state is denoted by the continuous time variable ``x``, which in reality represents a number of continuous states such that

$$
x \in \mathbb{R}^n,
$$

where ``n`` is the number of states (e.g. distance, velocity etc. ).
In order to transcribe the problem to a format compatible with our NLP problem, we must discretise this continuous states into a set of decision variables and dynamics constraints.
As such, we can represent the state as a function of a set of decision variables.
Let's take ``\tilde{x}`` to be some interpolating function which interpolates a state for a given number of inputs.
We then have

$$
\begin{equation}
\label{xState}
\pmb{x} = [\tilde{x}_i (t,x_i)], \quad x_i \in \mathbb{R}^{m_i}, \quad \tilde{x} : \mathbb{R}^{m_i + 1} \rightarrow \mathbb{R},  \quad i = 1,2 \ldots n,
\end{equation}
$$

such that ``t`` is the evaluation time of the interpolating function, ``m \in \mathbb{R}^n`` is the number of decision variables for each discretised state and may contain a different value at each state index ``i``, and ``x_i`` is a vector of interpolating data points.
The existence of this interpolating function is important and one of the primary motivations for this work.
In traditional dynamic optimisation problems, we are only ever aware of the dynamics and constraint violations at collocation points, information between is often determined at the end of a solve when some interpolation is applied.
Having such an interpolating function can provide us with more information during the solve and lead to better mesh refinement with the ultimate goal of reducing the number of collocation points while maintaining solution accuracy. 
One such example for ensuring accuracy would be to have a higher number of collocation points for the path constraint function, and a lower number for the system dynamics. 
As illustrated in section ``\ref{lagmath}``, function ``\tilde{x}`` can be initialised without knowledge of the specifics of ``t``.
The number of decision variables in not to be confused with the number of collocation points, which in many cases is the same but in some is different.
Collocation points are the points where system dynamics are enforced, but not all points where we approximate state have to comply with system dynamics.
Additionally, in the data point formulation (as opposed to the coefficient formulation) an individual data point ``\bar{x}_{ij}`` will consist of a mesh location and state value as below.

$$
\begin{equation}
\label{meshdef}
x_i = \big[ \bar{x}_{ij} = [t_{ij}, x_{ij}] \big], \quad x(t_{ij}) = x_{ij}, \quad j = 1,2, \ldots m_i.
\end{equation}
$$

Crucially ``x_{ij}`` are our decision variables.
These discretised states will go onto become decision variables in our NLP formulation.
Traditional formulations such as that in ICLOCS require states to be discretised at set mesh interval points such that ``\pmb{x} \in \mathbb{R}^{n\times m}``.
By the introduction of and interpolating function ``\tilde{x}``, we are no longer constrained to requiring the number of decision variables in each state to be the same.
In our formulation, ``\tilde{x}`` is an interpolating polynomial, hence the discussion in section ``\ref{lagmath}``.
This interpolating polynomial may be a function of polynomial coefficients, or interpolating data points, and for the rest of this discussion we will assume they are the latter.
As such, ``x_i`` represents a set of interpolating data points, and ``\pmb{x}`` represents a vector of state approximating functions such that ``\pmb{x}_i(t_k) = \tilde{x}_i(x_i,t_k)``, where ``\tilde{x}_i`` is the ``i^{\text{th}}`` state approximation evaluated at time ``t_{k}``.


Likewise, we may use the same definition for our control variables.
$$
\begin{equation}
\label{uControl}
\pmb{u} = [\tilde{u}_i (t,u_i)], \quad u_i \in \mathbb{R}^{m_i}, \quad \tilde{u} : \mathbb{R}^{m_i + 1} \rightarrow \mathbb{R},  \quad i = 1,2 \ldots c,
\end{equation}
$$

where ``c`` is the number of controls. 

Our system dynamics function is how we specify the dynamics (in many cases physics) of the system being optimised, and is represented as an array of functions, one for each state derivative.
Given we can calculate all state derivatives as a function of the states at one particular time instance, we can have a function mapping that outputs all the state dynamics for a particular state at collocation points given by a time vector ``\pmb{\tau} = [\tau_i] = [t_1, t_2 \ldots t_{m_i}], i = 1,2\ldots n``

$$
\begin{equation}
\label{ffunc}
\pmb{f} = f_i(\tau_i, \pmb{x}(t),\pmb{u}(t)) : \mathbb{R}^{(n + c) \times m_i} \rightarrow \mathbb{R}^{m_i}, \quad i = 1,2\ldots n
\end{equation}
$$

Where ``n`` is the number of both states and controls, and ``m_i`` is the number of collocation points for each state index ``i``.
Note that for each individual function evaluation, the input array ``\tau_i`` is assumed to have dimensions ``(n+c) \times m_i``, and as such we use our interpolating functions to find the values of states and controls at locations of ``\tau_i=t_k, k = 1,2\ldots m_i``.

Putting this all together we have
$$
\pmb{x}\left\{\begin{matrix}
\pmb{x}_1 =& \tilde{x}_1 (t,[\bar{x}_{11}, \bar{x}_{12} \ldots \bar{x}_{1m_1} ]) \\
 \ldots & \\ 
\pmb{x}_n =& \tilde{x}_n ( t,[\bar{x}_{n1}, \bar{x}_{n2} \ldots \bar{x}_{nm_n} ]) 
\end{matrix}\right.
$$
$$
n = \text{number of states}, m_i = \text{states mesh sizes}, i = 1,2\ldots n
\medskip
$$

$$
\pmb{u}\left\{\begin{matrix}
\pmb{u}_1 =& \tilde{u}_1 ( t,[\bar{u}_{11}, \bar{u}_{12} \ldots \bar{u}_{1m_1} ]) \\
 \ldots & \\ 
\pmb{u}_c =& \tilde{u}_n (t,[\bar{u}_{c1}, \bar{u}_{c2} \ldots \bar{u}_{cm_c} ]) 
\end{matrix}\right.
$$
$$
c = \text{number of controls}, m_i = \text{controls mesh sizes}, i = 1,2\ldots c
\medskip
$$
$$
\pmb{f}\left\{\begin{matrix}
\dot{x}^{(1)} =& f_1( \tau_1,\pmb{x}(t),\pmb{u}(t)) \\
 \ldots & \\ 
\dot{x}^{(n)} =& f_n( \tau_n,\pmb{x}(t),\pmb{u}(t)) 
\end{matrix}\right.
$$
$$
n = \text{number of states}, \tau_i = \text{state collocation points}, i = 1,2 \ldots n
\medskip
$$
We use ``\dot{x}^{(i)}`` to represent the continuous dynamics of the state at the collocation points.
In our formulation the time vector ``t`` does not necessarily have to have the same length or values for any one such function call, only that it must correspond with the number of output variables being assigned.
For example, if we are evaluating ``m_i`` collocation points, then when calling ``f_1(\tau_1,\pmb{x}(t), \pmb{u}(t))``, ``\tau_1`` here must be of length ``m_1``, but the mesh points of ``x_1`` to ``x_n`` do not have to correspond with the collocation points, and if they do not, they are interpolated.
Additionally, inside the function ``f_i``, ``\pmb{x}`` and ``\pmb{u}`` may actually be evaluated at any time as they are interpolating functions, not necessarily at just the collocation points.

Now that we have our system dynamics functions, we need to transform them into a format that can be solved with an NLP solver.
This is the process of transcription and we do this by creating a set of equality constraints that enforce system dynamics at our chosen collocation points.
At these points we can verify that the system satisfies the laws of physics (if the problem is physical).
However, between collocation points we do not enforce such laws, and solutions must be interpolated, from which we derive a certain amount of error from approximation.
Additionally, oscillations can occur between collocation points if the system is significantly ill-defined.

This process generally involves us approximating the derivatives of the state vector at our collocation points, and in some way equating these with our dynamics function.
There are many of these approximations, but the simplest of these (and the one that probably illustrates the point best) is the Euler method in equation ``\ref{euler}``.
Note here ``h_k`` is the timestep ``h_k = t_{k+1} - t_k`` and ``t_k \in \tau_i`` is the collocation point being evaluated.

$$
\frac{\partial \pmb{x}_{i}(t_k)}{\partial t} = \pmb{f}_{i}(t_k) \approx \frac{\pmb{x}_{i}(t_{k+1}) - \pmb{x}_{i}(t_k)}{h_k}
$$
$$
\begin{equation}
\label{euler}
\pmb{x}_{i}(t_{k+1}) - \pmb{x}_{i}(t_k) - h_k \pmb{f}_{i}(t_k) = 0
\end{equation}
$$

For the sake of consistency, ``\pmb{x}_i(t) = \tilde{x}_i(t,x_i)``, ``\pmb{f}_i(\tau) = f_i(\tau,\pmb{x}(t), \pmb{u}(t))``.
All other methods are extensions of this principle, but aim to have more accurate estimations of state derivatives at collocation points.
Take for example the trapezoidal method

$$
\begin{equation}
\label{trap}
\pmb{x}_{i}(t_{k+1}) - \pmb{x}_{i}(t_k) - \frac{h_k}{2} \big(\pmb{f}_{i}(t_k) + \pmb{f}_{i}(t_{k+1})\big) = 0
\end{equation}
$$

Here we take an average of the system dynamics at the ``k`` and the ``k+1`` collocation point (the derivation comes from the trapezoidal integration approximation, hence trapezoidal method).

Equations ``\ref{euler}`` and ``\ref{trap}`` are formulations of the system dynamics as equality constraints which are in the form of equation ``\ref{gfunceq}`` and thus solvable by an NLP solver. 
Let's use the simple example of a mass spring damper system to show how system dynamics can be collocated.
We assume a fixed starting location, and collocate the dynamics using equation ``\ref{euler}``.
The equations of interest are

$$
\pmb{x} = 
\begin{bmatrix}
x\\
\dot{x} 

\end{bmatrix}=
\begin{bmatrix}
x_1\\
x_2 

\end{bmatrix}
$$

$$
f(x(t_k)) = \begin{bmatrix}
\dot{x}\\ 
\ddot{x}
\end{bmatrix} = \begin{bmatrix}
x_2\\ 
- 2 \zeta\omega_n x_2 - \omega_n^2 x_1
\end{bmatrix}
$$

where ``x_1`` is mass position, ``\omega_n = \sqrt{\frac{k}{m}}`` and ``\zeta = \frac{c}{2m\omega_n}`` with the constants as defined in the code.

! BeginColBox()
```julia; results = "hidden"
function spring()
    k = 5
    m = 0.1
    c = 0.7
    ω_n = sqrt(k/m)
    ζ = c / (2*m*ω_n)
    h_k = 0.1
    t = collect(0:h_k:1)
    x1 = LagrangePoly(t, ones(Float64, length(t))) # x1 state mesh points
    x2 = LagrangePoly(t, zeros(Float64, length(t))) # x2 state mesh points
    function f(x1, x2) # system dynamics
        x1dot = x2
        x2dot = -2 * ζ * ω_n * x2 - ω_n^2 * x1
        return x1dot, x2dot
    end
    for i = 1:length(t) - 1
        f1,f2 = f(x1(t[i]), x2(t[i]))
        x1[i+1] = x1(t[i]) + h_k * f1
        x2[i+1] = x2(t[i]) + h_k * f2
    end
    return x1, x2, t
end

x1, x2, t = spring()

```
! EndColBox()
! BeginFig()
```julia; out_width="0.7\\textwidth"; echo=false
interpolated_t = collect(0:0.01:1)
plot(interpolated_t, x1.(interpolated_t), labels = ["interpolated" ""])
scatter!(t, x1.(t), xlabel="t", ylabel="x1", labels = ["collocated" ""])
```
! EndFig("Collocated system dynamics for a mass spring damper","massdamp")
Figure ``\ref{massdamp}`` shows the results.
The collocation points are marked with a circle, while the interpolated value (in this case using a high order polynomial) are marked by the line. 
Note the example code here is more akin to a shooting method rather than direct collocation but the results in this case are similar.

Next we will look into formulating our path and boundary constraints for the NLP problem.


### `j print(problemComponents[2])`
Almost all dynamic optimisation problems will require some form of constraint on our system.
Constraints can be categorised as either boundary constraints or path constraints.
Boundary constraints occur at the start and endpoints of the problem i.e. at ``t=t_1`` and ``t=t_F`` (as is consistent with Julia syntax we assume 1 is our initial value rather than 0).
Boundary constraints may either be fixed limits or a function of the boundary values.
In the case of fixed limits, we have
$$
t_{1,L} \leq t_1 \leq t_{1,U}
$$
$$
t_{F,L} \leq t_F \leq t_{F,U}
$$
$$
\pmb{x}_{i,L}(t_1) \leq \pmb{x}_i(t_1) \leq \pmb{x}_{i,U}(t_1)
$$
$$
\pmb{x}_{i,L}(t_F) \leq \pmb{x}_i(t_F) \leq \pmb{x}_{i,U}(t_F)
$$

which are all perturbations of equation ``\ref{xineq}``.
Examples of fixed limits would be wanting to finish at a particular location, or with no fuel left etc.

Additionally, we may formulate constraints as a function of boundary values
$$
\pmb{b}(t_1,t_F,\pmb{x}(t_1),\pmb{x}(t_F)) \leq 0
$$
which again can be represented in our NLP solver by equation ``\ref{gfunc}``.
An example of a boundary constraint function would be a function ensuring that the final speed of a spacecraft matches that of a space station in orbit.

Path constrains follow an almost identical formulation but apply to the whole of the path through time and consider control input as well.
$$
\begin{equation}
\label{xpath}
\pmb{x}_{i,L} \leq \pmb{x}_i(t_{ij}) \leq \pmb{x}_{i,U}
\end{equation}
$$
$$
\begin{equation}
\label{upath}
\pmb{u}_{i,L} \leq \pmb{u}_i(t_{ij}) \leq \pmb{u}_{i,U}
\end{equation}
$$
$$
\begin{equation}
\label{bpath}
\pmb{h}( \pmb{\tau}^{(h)},\pmb{x}(t),\pmb{u}(t)) \leq 0
\end{equation}
$$
For the sake of completeness equations ``\ref{xpath}`` and ``\ref{upath}`` correspond to equation ``\ref{xineq}`` and equation ``\ref{bpath}`` to equation ``\ref{gfunc}`` in our NLP formulation.
Again let's look at a graphical representation to illustrate this using the example from figure ``\ref{massdamp}``.
Let's add the following constraints to our problem.

$$
\begin{equation}
\label{expathcon}
-1 \leq \pmb{x}_1(t_k) \leq 1
\end{equation}
$$
$$
\begin{equation}
\label{exhcon}
h_1(t_k,\pmb{x}(t_k),\pmb{u}(t_k))  = \pmb{x}_1(t_k) + t_k - 1.5 \leq 0
\end{equation}
$$
For the example ``h_1`` could represent a desire for the oscillations to grow smaller with time, while the path constraint could represent physical stops on the system which stop the spring moving beyond this point.
We can tailor the constraints to fit both the problem dynamics and our specific goals.

! BeginFig()
```julia; out_width="0.7\\textwidth";echo=false
rect(w, h, x, y) = Shape(x .+ [0, w, w, 0, 0], y .+ [0, 0, h, h, 0])
h = Shape([0,1,1,0],[1.5,0.5,2,2])
plot(rect(1,1,0,-2), labels = ["" ""], fillcolor =plot_color(:black,0.3))
plot!(rect(1,1,0,1), labels = ["" ""], c = plot_color(:black,0.3))
plot!(h, labels = ["" ""], c = palette(:default)[2])
plot!(interpolated_t, x1.(interpolated_t), xlabel="t", ylabel="x1", labels = ["interpolated" ""],c=palette(:default)[1])
scatter!(t, x1.(t), xlabel="t", ylabel="x1", labels = ["collocation points" ""])
```
! EndFig("Example inequality constraints from equations \\ref{expathcon} and \\ref{exhcon}","pathconfig")

The constraint in equation ``\ref{expathcon}`` is violated in the grey area in figure ``\ref{pathconfig}``, the equation ``\ref{exhcon}`` is violated in the orange region.
We observe that a small portion of the state violates the path constraint above ``x_1 = 1``, but also note that the path constraint is still entirely satisfied at the collocation points at ``t=0`` and ``t=0.1``, and it it a result of our interpolation that the constraint is violates.
To the NLP solver, this violation is invisible, as we only ensure path constraints at collocation points.
Hence the motivation for this work, that is, having the ability to evaluate the function at points other than collocation points can help us refine the mesh spacings / collocation points in order find a more accurate solution.
One course of action here would be to increase the number of collocation points associated with the path constrains.
Nonlinear constraint functions such as ``h`` and ``b`` need not merely constrain one variable, and in many cases will be a combination of many, but this would be more difficult to represent graphically.
If boundary constraints were enforced, we would then consider the restrictions on the state at time ``t=0`` and ``t=1``.


Finally we will look at the objective function formulation.

### `j print(problemComponents[3])`
The objective function to be minimised is divided into a Mayer term and a Lagrange term.
The Mayer term is a function of the boundary conditions, while the Lagrange term is a function of the whole state trajectory through time.
Together they form the Bolza problem

$$
\begin{equation}
\label{bolza}
J(\tau^{(\rho)},\pmb{x}(t),\pmb{u}(t)) = \underbrace{\Phi(t_1,t_F,\pmb{x}(t_1),\pmb{x}(t_F)) }_{\text{Mayer term}} + \underbrace{\int_{t_1}^{t_F} \rho (\tau^{(\rho)}, \pmb{x}(t), \pmb{u}(t)) dt}_{\text{Lagrange term}} 
\end{equation}
$$

The nonlinear function in equation ``\ref{bolza}`` maps directly to equation ``\ref{objectiveFunc}`` in our NLP problem.
With regards  to the Lagrange term, there are a few options for calculating the integral.
If no interpolating function is used, we could use a basic approximation

$$
\int_{t_1}^{t_F} \rho (\tau^{(\rho)}, \pmb{x}(t), \pmb{u}(t)) dt \approx \sum_{k=1}^{m-1} \frac{1}{2} (h_k)\rho(\tau^{(\rho)}_k,\pmb{x}(t),\pmb{u}(t))
$$

Alternatively, if the objective function is modelled with an interpolating function, we can calculate the exact integral of the interpolation as per equation ``\ref{lgrint}``.

This completes our formulation of the dynamic optimisation problem. 

## Example implementation in ICLOCS

## Lagrange polynomials
! Label("lagmath")
Now we will discuss the background for the interpolating functions used to approximate state and control functions (and potentially the objective function), which will lead us to a discussion of the pseudospectral dynamic optimisation method.
Lagrange interpolating polynomials in the barycentric form are useful for fast polynomial interpolation and are forward stable for problems with mesh points clustered towards the ends of intervals ``\cite{Higham2004TheInterpolation}``.
Using ``t_k`` and ``t_j`` to represent our mesh points, and ``y`` to represent our function evaluations at points of ``t_k`` and ``t_j`` such that ``y = f(t_{k,j})``, the unmodified Lagrange formula is

$$
\begin{equation}
\label{lagweight}
l_j(t) = \prod_{k=1,k\neq j}^{m} \frac{t - t_k}{t_j - t_k}
\end{equation}
$$
$$
L(t) = \sum_{j=1}^m  y_j l_j(t)
$$

We take ``m`` to be the number of mesh points (as before in section ``\ref{dynamicsmath}``), ``t`` to be the evaluation point, ``L`` is the output of our interpolation at ``t`` and ``l_j`` are intermediary Lagrange weights.
The denominator of equation ``\ref{lagweight}`` is a function of the mesh points and not of the evaluation point ``t``.
As such, we can precompute these beforehand and use them when evaluating our polynomial interpolation.
This gives us the barycentric form of our polynomial

$$
\begin{equation}
\label{barweight}
w_j = \frac{1}{\prod_{k=1,k\neq j}^m(t_j - t_k)}
\end{equation}
$$

$$
\begin{equation}
\label{lagbar}
L(t) = \frac{\displaystyle \sum_{j=1}^m \frac{w_j}{t-t_j} y_j}{ \displaystyle \sum_{j=1}^m \frac{w_j}{t-t_j}}
\end{equation}
$$

Where ``w`` are barycentric weights.
Note that the weights are purely a function of the mesh points (the domain of the polynomial) and not of the reference evaluations ``y`` at the mesh points.
This means we can calculate our polynomial weights without knowledge of the function outputs at mesh points (in this case ``y``), and thus if we want to update our polynomial approximation (providing our mesh spacing is the same) all we need do is update our output values which we use for interpolation. 
No further computation of the weights is required, and the cost of adding additional weights is much lower than recalculating our approximation.

### Differentiation matrix
! Label("lagpolyder")

Having constructed our polynomial in the barycentric form, we can also calculate the differentiation matrix such that

$$
\begin{equation}
\label{Ldot}
\dot{L}(t) = \sum_{j=1}^m  \bar{y}_j l_j(t), \quad \bar{y} = Dy,
\end{equation}
$$

where ``y`` is a column vector.
The differentiation matrix ``D`` is defined as
$$
D_{ij} = \left\{\begin{matrix}
\displaystyle \frac{w_j}{w_i(t_i-t_j))}, & i\neq j \\ 
\\
\displaystyle \sum_{k=0,k\neq i}^m \frac{1}{t_i-t_k},& i = j 
\end{matrix}\right.
$$


## The pseudospectral method
The pseudospectral method is of particular interest as its formulation allows us to exploit the use of the interpolating polynomial described in section \ref{dynamicsmath}
Using interpolating polynomials for our ``\tilde{x}`` function has the benefit of having derivative information encoded in the polynomial itself (see section ``\ref{lagpolyder}``).
As such, we can use this information, along with a particular distribution of mesh points, to formulate the pseudospectral methods for dynamic optimisation.
There are a few different formulations of the pseudospectral method, but to keep things simple we will assume a single polynomial approximates each state and control.
More complex formulations include multiple piecewise polynomials approximating each state and control, but this complicates derivative formulation.
Additionally, we will be focusing on using Legendre-Gauss-Radau (LGR) points to approximate our polynomial, which are defined on the interval ``[-1,1)``.
LGR points are the solution to the polynomial 
$$
P_N(x)+P_{N-1}(x) = 0,
$$
where ``P_N`` are Legendre polynomials. 
! BeginFig()
```julia;echo=false;out_width="0.7\\textwidth"
scatter(lgr_points(7),[0,0,0,0,0,0,0],xlabel="t",ylabel="",labels=["LGR points" ""], ylims=(-1,1),showaxis=:x )

```
! EndFig("Seven LGR Points","lgrfig")

We use the LGR points as a base for the interpolating polynomial mesh, such that ``t_{ij}`` in equation ``\ref{meshdef}`` are the LGR points.
As the LGR points are defined on the interval ``[-1,1)``, we can use the following transformation to transform from ``[-1,1]`` to ``[-t_1,t_F]``.
$$
\begin{equation}
\label{timetrans}
\bar{t} = \frac{t_1-t_F}{2} t + \frac{t_1+t_F}{2}.
\end{equation}
$$
If we know our interpolating points correspond with LGR points, we can also use the LGR weights ``w_{LGR}`` to calculate the exact integral.
$$
\begin{equation}
\label{lgrint}
\int_{-1}^1 x(t)dt = \sum_{k}^m w_{LGR,k} x(t_k)
\end{equation}
$$
This is useful for determining the object function, or for approximating endpoints as below.

Now we can use the derivate information of our polynomial to enforce our system dynamics
$$
\begin{equation}
\label{psecoloc}
\dot{\tilde{x}}_i(\tau_i,x_i) - f_i(\tau_i,\pmb{x}(t),\pmb{u}(t)) = 0, \quad i=1,2\ldots n,
\end{equation}
$$
where ``t=t_1,t_2,\ldots t_{m_i}`` is a vector of collocation points for this state and ``\dot{\tilde{x}}`` is acquired from equation ``\ref{Ldot}``.
As in this formulation our LGR points do not include the endpoint, we must construct an interpolating constraint for this too.
$$
\pmb{x}_i(t_F) = \pmb{x}_i(t_1) + \int_{-1}^1 \dot{x}^{(i)}(t)dt \approx \pmb{x}_i(t_1) + w_{LGR} \pmb{f}_i(\tau_i)
$$

Here ``t_1=-1, t_F = 1``.
Use equation ``\ref{timetrans}`` to transform to the time domain of the optimisation problem.
Additionally, ``w_{LGR}`` is a row vector, and ``\pmb{f}_i`` is a column vector, such that ``w_{LGR}\pmb{f}_i \rightarrow \mathbb{R}^{m_i}``.
Note we can avoid this additional constraint by using a set of flipped LGR points.
It is useful to know however as some pseudospectral methods are defined on the interval (-1,1).

Finally, the full pseudospectral LGR formulation of the dynamic optimisation problem is

$$
\begin{align*}
\min & \quad J(\tau^{(\rho)}, \pmb{x}(t), \pmb{u}(t)) = \Phi(t_1,t_F, \pmb{x}(t_1),\pmb{x}(t_F)) + w_{LGR} \tilde{\rho}(\tau^{(\rho)},\pmb{x}(t),\pmb{u}(t))   \\
\text{s.t.} & \quad \dot{\pmb{x}}(\pmb{\tau}) - \pmb{f}(\pmb{\tau},\pmb{x}(t),\pmb{u}(t)) = 0 \\
& \quad  \pmb{x}(t_F) - \pmb{x}(t_1) - w_{LGR}\pmb{f}(\pmb{\tau}) = 0\\
& \quad t_{1,L} \leq t_1 \leq t_{1,U} \\
& \quad t_{F,L} \leq t_F \leq t_{F,U} \\
& \quad \pmb{x}_{,L}(t_1) \leq \pmb{x}(t_1) \leq \pmb{x}_{,U}(t_1) \\
& \quad \pmb{x}_{,L}(t_F) \leq \pmb{x}(t_F) \leq \pmb{x}_{,U}(t_F) \\
& \quad \pmb{b}(t_1,t_F,\pmb{x}(t_1),\pmb{x}(t_F)) \leq 0 \\
& \quad \pmb{x}_{,L} \leq \pmb{x}(\pmb{\tau}) \leq \pmb{x}_{,U} \\
& \quad \pmb{u}_{,L} \leq \pmb{u}(\pmb{\tau}) \leq \pmb{u}_{,U} \\
& \quad \pmb{h}( \pmb{\tau^{(h)}},\pmb{x}(t),\pmb{u}(t)) \leq 0 \\
& \end{align*}
$$

## Julia packages
There are 2 packages which are referred to at length in this text which may be worth introducing.
These are the Polynomials.jl and JuMP.jl packages.
### Polynomials.jl
! Label("polynomialsjl")
Polynomials.jl is a package by JuliaMath, and adds the ability to create, differentiate and integrate coefficient based polynomials.
The interface is simple but intuitive, which is one of the key reasons for choosing it as a package to extend, the other being that it is well maintained.
The goal of this project is to extend Polynomials.jl to cover a verity of Lagrange interpolating polynomials which can be used in dynamic optimisation, as well as add a few new features along the way.
To summarise, Polynomials.jl is good, but we can make it better.
### JuMP.jl
JuMP.jl is a package by Julia Computing which aims to provide a standard interface to a number of linear, quadratic and nonlinear programming solvers.
JuMP.jl allows us to interface with Ipopt through a number of JuMP.jl decision variables, constraints and user defined functions.
Like many Julia packages in their infancy, JuMP.jl is under heavy development and the interface is somewhat restrictive in its current implementation.
Nonetheless, it abstracts well much of the complexities associated with MathOptInterface.jl, the package which acts as a wrapper for a number of solvers.
To this end, JuMP.jl is an NLP solver wrapper wrapper.



# Project Ethos
! Label("ethos")
The main aims of the project are derived from lessons learnt in ICLOCS, and are as follows:
```julia; echo=false; results="hidden"
aims = ["Code structure must be modular",
        "Code must be sufficiently verbose when handling errors",
        "Code must verify data before computation",
        "The final package must be user extensible and have the ability to support multiple solvers",
        "Location of mesh points for each state must be independent of other states",
        "The MorePolynomials.jl package must interface well with the existing Polynomials package"];
```
1) `j print(aims[1])`
2) `j print(aims[2])`
3) `j print(aims[3])`

* JuDO.jl
4) `j print(aims[4])`
5) `j print(aims[5])`
    

* MorePolynomials.jl
6) `j print(aims[6])`

## `j print(aims[1])`
! Label("aimmodular")
It has been identified that the ICLOCS package has reached a feature saturation point, such that further expansion would require a large proportion of code to be rewritten.
One of the primary aims of this project is to write code which is sufficiently extensible by leveraging features in Julia such as types and multiple dispatch that allow for greater code separation. 
Examples of this can be found in section ``\ref{morepoly}``, where multiple dispatch and abstract typing allow us to utilise existing functions in the Polynomials.jl package while extending it to work with our own function definitions.
This would be far more difficult in a traditional OOP based language.

## `j print(aims[2])`
When describing the dynamic optimisation problem, the use of verbose error handling and user feedback is extremely useful in guiding the user to both a solvable and well constructed problem.
This was particular apparent in the formulation of problems in the ICLOCS package.
Often errors in the user defined problem (UDP) would result in error traces that lead deep into the core of the code, providing little help to the user who's only course of action would be to trace the flow of data through the source code of ICLOCS.
The aim of this new package is to catch errors elegantly, and give the user contextual feedback.

## `j print(aims[3])`
Closely related to well implemented error handling is the verification of the data in the first place.
The phrase garbage in garbage out is relevant here.
If we ensure the quality of the UDP before any computation, we can ensure the speed and freedom from errors in the results.
The reverse is true, that if no verification takes place, the UDP could result in hard to debug errors embedded in the source code, which is not where we want them.
By leveraging Julia's explicit type system, we can remove potential conversion errors further down the line by internally specifying the types of the components of the UDP.
Further pre solve check can ensure the quality and compatibility of the UDP with internal solver interfaces.
This also has the added benefit of speeding up computation when the compiles is aware of the types at runtime.

## `j print(aims[4])`
This is particular important for the longevity of the project.
Bespoke programs could be created for each individual solver, but a more ideal solution would be to create a generic framework from which additional solvers can be plugged in.
This is highly dependent on the nature of each solver, and additional solver specific syntax may need to be included in the UDP (e.g. if the solver is not black box, additional derivatives may need to be provided unless numerically calculated).
However, this goal is more focused towards ease of future development, rather than the user interface.

## `j print(aims[5])`
! Label("indepmeshaim")
By isolation of each state, we can vary the density of mesh points for each state.
As such, states which can be approximated by a smaller mesh size do not occupy unnecessary space in memory due to other states requiring a larger mesh size to achieve an accurate approximation.
This can be achieved by interpolating the state at collocation points when required.

## `j print(aims[6])`
As Polynomials.jl is a rapidly developing package, ensuring compatibility allows for easy integration of future features.
As Julia is an ever evolving language, by building off pre-existing packages we can make the MorePolynomials.jl packages appealing for users already familiar with the framework, while reducing developer load on are part as Polynomials.jl is updated with Julia updates.
The disadvantage being we are then at the mercy of the Polynomials.jl package developers.
If they decided to change their framework entirely, our package may also need to change.
This is not necessarily an issue however as we can specify backwards compatibility.



# Results and Discussion
In order to address the goals in section ``\ref{ethos}``, two packages have been developed which address different but related goals.
The first package, Julia dynamic optimisation (JuDO.jl) is a dynamic optimisation toolbox in Julia with the aim of supporting multiple solvers (currently only JuMP.jl has been implemented).
The second package, MorePolynomials.jl, is an extension of the aforementioned Polynomials.jl package (see section ``\ref{polynomialsjl}``).

We will begin with a discussion of the MorePolynomials.jl package.

## MorePolynomials.jl
! Label("morepoly")
MorePolynomials.jl aims to address the need for polynomial representations of state and control vectors in dynamic optimisation problems, while being generic enough to be used with other applications.
As not to reinvent the wheel (though much wheel reinventing is present in the wild west that is the Julia package library), it is built as an extension to the Polynomials.jl package.
One advantage of this is by subtyping our polynomials from the `AbstractPolynomial` type, we can make use of many of the generic polynomial functions without having to write additional code.
Unfortunately much of this code 'inheritance' (though not to be taken in the traditional manner) relies in this case on having a matching backend data representation, which is not the case.
All is not lost however, as we can dispatch on our own custom types and essentially just rewrite the necessary subroutines for our polynomials.
Take the example of the `fit()` command from Polynomials.jl.
! BeginColBox()
```julia;eval=false
function fit(P::Type{<:AbstractPolynomial},
             x::AbstractVector{T},
             y::AbstractVector{T},
             deg::Integer = length(x) - 1;
    weights = nothing,
    var = :x,) where {T}
    x = mapdomain(P, x)
    vand = vander(P, x, deg)
    if weights !== nothing
        coeffs = _wlstsq(vand, y, weights)
    else
        coeffs = pinv(vand) * y
    end
    return P(T.(coeffs), var)
end
```
! EndColBox()

This function assumes the existence of the `coeffs` data structure, which does not exist in our present formulation.
As such, we dispatch on the function with our own implementation.
In the case of the `LagrangePoly`, we have
! BeginColBox()
```julia;eval=false
function fit(P::Type{<:AbstractLagrangePolynomial}, x::AbstractVector{T}, y::AbstractVector{T}; var = :x) where {T}
    return LagrangePoly(x,y;var)
end
```
! EndColBox()
Others can be directly inherited from the package without any code additions.
For example in the case of the roots function in Polynomials.jl
! BeginColBox()
```julia;eval=false
function roots(q::AbstractPolynomial{T}; kwargs...) where {T <: Number}
    p = convert(Polynomial{T},  q)
    roots(p; kwargs...)
end

```
! EndColBox()
Here the `AbstractPolynomial` is converted to type `Polynomial` and then the roots can be found based on the internal `Polynomial` type.
As long as we implement the `convert()` function for our polynomial and the `Polynomial` type, we need not dispatch on the `roots()` function.
The important thing is that to the user it makes no difference thanks to the power of multiple dispatch.

MorePolynomials.jl adds the following additional functionality to the Polynomials.jl package.
* Fast fitting of low order polynomials using precomputed symbolic expressions
* Lagrange interpolating polynomials in barycentric form
* Lagrange polynomial differentiation and differentiation matrices
* Legendre-Gauss-Radau based Lagrange polynomials with integration
* Combination piecewise polynomials with infinite bound mapping
* Legendre polynomials

We will now take a closer look at the backend implementation of MorePolynomials.jl.

### Lagrange implementation
The Polynomials.jl package has the following data structure which allows polynomial to be stored using its coefficients.
! BeginColBox()
```julia;eval=false
struct Polynomial{T <: Number} <: StandardBasisPolynomial{T}
    coeffs::Vector{T}
    var::Symbol
end
```
! EndColBox()

As the standard `Polynomial` type from `Polynomials.jl` already provides and interface for storing coefficient based polynomials, an additional data structure and supporting subroutines has been introduced to implement the Lagrange polynomial.
! BeginColBox()
```julia;eval=false
mutable struct LagrangePoly{T<:Number} <: AbstractLagrangePolynomial{T} 
    x::Vector{T}
    y::Vector{T}
    weights::Vector{T}
    domain::Interval{T}
    var::Symbol
end
```
! EndColBox()

Take note of a couple of features.
First, we have chosen to use `x` and `y` to represent our mesh points and function evaluation points respectively, which is inconsistent with the notation in this text.
This is by choice to maintain consistency with the Polynomials.jl package, and is mentioned here as many additional decisions of notation in this package have been chosen for similar reasons.
Seconds, the types of all fields (excluding `var`) are parameterised and forced to be the same.
The benefits of this are twofold: we don't have to call convert functions when execution any computation that is a function of more than one field, and the compiler is fully aware of the type at runtime, and thus can optimise operations for this type, leading to significant performance gains.
This choice of representation is made for the benefit gain in polynomial creation and alteration, at the expense of larger memory presence and evaluation time.

To illustrate the differences between the two representations, let's benchmark some polynomials.
We'll use 6 points for a 5th order polynomial, which will give us an exact representation.
Note the fact that we have an exact representation should not affect the benchmarking results as the same number of operations are taking places.
First, let's start with polynomial fitting
! BeginColBox()
```julia
t = [-1,-0.6,-0.2,0.2,0.6,1]
y = @. t^5 + 3t^2 - t + 1
# y points for a 5th order polynomial t^5 + 3t^2 - t + 1

mean(@benchmark fit(Polynomial, t, y)) # using Polynomials.jl
```
```julia
mean(@benchmark fit(LagrangePoly, t, y)) # using MorePolynomials.jl
```
! EndColBox()
This is perhaps an unfair comparison as Polynomials.jl has the additional step of converting to a coefficient representation.
A more fair comparison would be from time to polynomial creation to first evaluation.
Let's time the creation and evaluation of the polynomial at point `t=0.25`.
! BeginColBox()
```julia
mean(@benchmark fit(Polynomial, t, y)(0.25)) # using Polynomials.jl
```
```julia
mean(@benchmark fit(LagrangePoly, t, y)(0.25)) # using MorePolynomials.jl
```
! EndColBox()

We observe a minor time increase in both cases but MorePolynomials.jl is still almost an order of magnitude faster.
This is largely due to the barycentric representation, which uses barycentric weights to speed up the evaluation of the polynomial, allowing an evaluation time in the order of ``\mathcal{O}(n)`` flops.
This incurs overhead when generating the weights for the polynomial, but this is still significantly faster than the least-squares approximation employed by Polynomials.jl.
Internally, the generation of weights takes the following form
! BeginColBox()
```julia; eval=false
function lagrange_bary_weights(x::AbstractVector{T}) where {T}
    numPoints = length(x)
    w = ones(T,numPoints)
    for j in 2:numPoints
        xj = x[j]
        for k in 1:j-1
            w[k] *= x[k] - xj
        end
        for k in 1:j-1
            w[j] *= xj - x[k]
        end
    end
    return 1 ./ w
end
```
! EndColBox()

This achieves the same result as equation ``\ref{barweight}``.
The exact number of flops required to calculate the weights is ``n\times (n - 1)``.
We execute the same for loop twice so to take advantage of the cpu cache when indexing the final weight.

As mentioned in section ``\ref{lagmath}``, the barycentric representation allows us to update our interpolation points (``y_j``) without having to recompute weights if our mesh points are the same.
This can be particularly useful for dynamic optimisation problems, where the states are perpetually changing but the mesh remains the same between solves.
We demonstrate this below using `lPoly[:] = ynew`

! BeginColBox()
```julia
lPoly = fit(LagrangePoly, t, y)
ynew = @. 5t^5 + 7t^4 - 3t - 1
# update our y values in lPloly and evaluate at t
updateAndEval(lPoly, ynew, t) = lPoly[:] = ynew; lPoly(t) 
mean(@benchmark updateAndEval(lPoly, ynew, 0.25)) 
```
! EndColBox()

Differentiation as per equation ``\ref{Ldot}`` has also been implemented in the barycentric form, and works identically to the derivative function in Polynomials.jl.
When we differentiate a polynomial, we receive a new polynomial representing the differential of the input polynomial.
! BeginColBox();
```julia; results="hidden"
lPolyDer = derivative(lPoly)
```
! EndColBox()
! BeginFig()
```julia; echo=false;out_width="0.7\\textwidth"
xinterp = collect([-1:0.05:1])
plot(xinterp, lPolyDer.(xinterp), xlabel="t", ylabel="y", labels=["" ""])
```
! EndFig("lPolyDer plot","lderpolyplot")
Once again due to the barycentric implementation the fitting to derivative time exceeds that of the Polynomials.jl package.
! BeginColBox()
```julia
mean(@benchmark derivative(fit(Polynomial, t, y))(0.25)) # using Polynomials.jl
```
```julia
mean(@benchmark derivative(fit(LagrangePoly, t, y))(0.25)) # using MorePolynomials.jl
```
! EndColBox()
What's more, if we intend to recalculate derivatives using the same mesh spacing, MorePolynomials provides a function for the derivative matrix, which when stored saves us having to recalculate it every time we update our function interpolation points.
We demonstrate this below using `lPolyDer[:] = derivmatrix*ynew`
! BeginColBox()
```julia
D = derivmatrix(lPoly)
ynew = @. 7t^5 + 9t^4 - t - 2
# update our y values and recalculate derivative
updateDerivAndEval(lPolyDer, ynew, D, t) = lPolyDer[:] = D*ynew; lPolyDer(t) 
mean(@benchmark updateDerivAndEval(lPoly, ynew, D, 0.25)) 
```
! EndColBox()

An extension of the Lagrange polynomial is the Legendre-Gauss-Radau Lagrange polynomial [^1].
This uses LGR points to generate the mesh.
See this paper on the benefits of using LGR points of function approximation in dynamic optimisation ``\cite{GargAnProblems}``.
The current implementation finds the LGR points as a function of the eigenvalues of a symmetric Legendre polynomial based matrix, but future implementations will most likely use a combination of this method and the implementation in the package FastGaussQuadrature, dynamically switching based on speed of implementation and number of points.
For the moment, our implementation is faster at low orders.
Additionally, if the mesh points follow the LGR formulation, we can make use of the LGR weights generated from FastGaussQuadrature for fast integration.
Let's now compare some polynomial integration between Polynomials.jl and MorePolynomials.jl.

[^1]: Try saying that really quickly many times in a row!

! BeginColBox()
```julia
x = lgr_points(6)

mean(@benchmark integrate(fit(Polynomial, t, y)),0) # using Polynomials.jl
```
```julia
mean(@benchmark integrate(fit(LGRPoly, y))) # using MorePolynomials.jl
```
! EndColBox()
And just for fun let's compare this to a similar implementation in matlab (output is in seconds)

! BeginColBox()
```julia
open(`matlab -nodesktop -nosplash`, "w", stdout) do io
    println(io,"t = $t;")
    println(io,"y = $y;")
    println(io,"int = @() polyint(polyfit(t,y,5));")
    println(io,"time_taken = timeit(int)")
end
```
! EndColBox()

### Low order Vandermonde methods
Depending on the system dynamics and constraints, it may be beneficial to, rather than having one high order, approximate states or controls using a series of low order polynomials.
One method for analytically determining coefficients of polynomials from data points is by inversion of the Vandermonde matrix.
Computationally, this is quite expensive, especially as the size of the matrix grows quadratic as the order of the polynomial increases.
For low order polynomials however, it is reasonably easy to use a symbolic solver to calculate the inverse of the Vandermonde matrix analytically.
This process is still slow, but if the analytical solution can be solved at compile time, and then somehow inserted directly into our code, we can achieve extremely fast runtime calculation of coefficient of low order polynomials.
Thankfully Julia macros provide a useful interface for generating code at compile time and, together with the Reduce.jl package for symbolic maths, we can do just that.
We start by generating the analytical solution to the inverse of the Vandermonde matrix.
! BeginColBox()
```julia
leny = 2 # number of data points
symX = []
symY = []
A = Array{Expr}(undef, leny, leny)
for i = 1:leny
    push!(symX, Meta.parse("x$i"))
    push!(symY, Meta.parse("y$i"))
end
for i = 1:leny # Assemble A matrix
    for j = 1:leny
        pwr = leny-j
        var = symX[i]
        A[i,j] = :($var^$pwr)
    end
end
coefs = Algebra.:*(Algebra.inv(A),symY) # invert to find coefs of polynomial
```
! EndColBox()

Here we being by defining an `A` matrix, which will be our Vandermonde matrix.
We go onto populate it with Julia symbols, which Julia can substitute in at a later stage with variables of the same name.
Finally we invert the matrix and get our analytic solution.
The implementation within MorePolynomials.jl then uses a macro to substitute these `x` and `y` values with the user's variables, resulting in an extremely fast low order polynomial coefficient calculator.
We can go on to calculate up to 4th order polynomials before the solution becomes too complex to calculate analytically.
Let's compare this method to a Lagrange fitting method at runtime.

! BeginColBox()
```julia
x = [0,0.2,0.4,0.6,0.8] 
y = @. x^4 + x^3 + 2x^2 + 5
mean(@benchmark fit(LagrangePoly, x, y)(0.25)) # using Lagrange poly fitting
```
```julia
mean(@benchmark vandpoly(x, y)(0.25)) # using Lagrange poly fitting
```
! EndColBox()

### Piecewise polynomials
Now that we have our low order polynomials, it would be useful to have a method for assembling them into a single piecewise polynomial.
This is achieved in the MorePolynomials.jl package using a custom `GlobalPoly`, which allows for the assembling of multiple polynomials.
Here we can also check for continuity between polynomials, and set domain mapping e.g. a polynomial defined over ``[-1,1]`` may be mapped to a polynomial with domain ``[t_1,t_2]``.
Additionally, we can assemble a polynomial of different types of polynomials, such that portions of the piecewise polynomial could be a high order Lagrange polynomial, while other could be low order coefficient defined polynomial.
To avoid confusion, we refer to the polynomials which make up the piecewise polynomial as local polynomials, and the piecewise polynomial as the global polynomial.
This terminology makes more sense when discussing mapping of local domains to the global domain.
Domain information of the local polynomial is defined within the polynomial type as in the example below.
Note we use the shorthand `LagrangePoly()` notation here such that `LagrangePoly(x, y) = fit(LagrangePoly, x, y)`

! BeginColBox()
```julia
p = LagrangePoly([-1.0, 0, 1], [1.0, 2, 3])
print(domain(p))
```
! EndColBox()
`GlobalPoly` can use this information when mapping a local polynomial to a global polynomial such that ``[t_1,t_F] \rightarrow [\bar{t}_1, \bar{t}_F]``.
The syntax is ``\text{GlobalPoly}(\text{localPoly}, \bar{t}_1, \bar{t}_F)``
Let's build an example `GlobalPoly` using a combination of Lagrange and coefficient polynomials.
! BeginColBox()
```julia;results="hidden"
p1 = LagrangePoly([-1.0, -0.6, -0.2, 0.2, 0.6, 1], [-5.0, 2, 3 ,20, 4, 2])
p2 = vandpoly([1, 1.5, 2], [2.0, 15, -5])
piecewisePoly = GlobalPoly(p1, 0.0, 1.0)
push!(piecewisePoly, p2, 1.0, 2.0)
piecewisePoly = push!(piecewisePoly, p1, 2.0, 3.0)
```
! EndColBox()
! BeginFig()
```julia; echo=false;out_width="0.7\\textwidth"
x = collect(0:0.01:3)
plot(x, piecewisePoly.(x), xlabel = "t", ylabel = "y")
```
! EndFig("Piecewise plot","gloplot")
Internally the implementation runs a series of checks when a new polynomial is added.
These checks ensure the mapped domains of the polynomials do not overlap, that the mapped domain is feasible (in the case of infinite domain mappings) and that the resulting piecewise polynomial is continuous.
With regards to infinite domain mapping, some infinite-horizon dynamic optimisation problems (where ``t_F=\infty``) require a transformation from a domain of ``[-1,1]`` to ``[0,\infty]``.
This can be achieved by the transformation
$$
\bar{t} = \frac{1+t}{1-t}.
$$
We can achieve such a mapping using `GlobalPoly`

! BeginColBox()
```julia
p = LagrangePoly([-1.0, 0, 1], [1.0, 2, 3])
infPoly = GlobalPoly(p, 0.0, Inf)
println("at (t = 1) p has value $(p(1)), at (t ≈ ∞) infPoly have value $(infPoly(exp(100)))") 
```
! EndColBox()
`GlobalPoly` has a system for deciding which transformation to use when using infinite domains in either the local or global poly domains based on intuition.
For example, for a mapping of ``[-t,t] \rightarrow [-\infty,\infty]`` `GlobalPoly` will first use the linear transform ``[-t,t] \rightarrow [-1,1]``, followed by the transform 
$$
\bar{t} = \tan\big(\frac{\pi t}{2}\big).
$$
On the other hand, the mapping ``[-\infty, \infty] \rightarrow [-t,t]`` assumes the user only wants the subset of the local polynomial between ``-t`` and ``t`` as the majority of organic polynomials defined over ``[-\infty,\infty]`` only contain useful information over a certain domain.


### User interface
The challenge of any user interface is to balance the exposure provided to the user of complex functionality with the ability to remain intuitive and simple to use.
This is more apparent when designing a graphical user interface, but elements of this are apparent in any interface.
By far, one of the key elements to maintaining an intuitive interface is consistency.
As previously stated one of the objectives of the MorePolynomials.jl package is to maintain close compatibility with Polynomials.jl.
One aspect of maintaining this compatibility is being consistent with maintaining the intent of user functions, and Julia's multiple dispatch system is well suited for this role.

Take the `fit()` command for example.
In Polynomials.jl, if we want to fit a polynomial to a set of data points, we have two arguments, the `x` values and the `y` values
! BeginColBox()
```julia;eval=false
fittedpoly = fit(x, y)
```
! EndColBox()
In MorePolynomials.jl, we extend this function to cover our custom polynomials using the method provided by Polynomials.jl
! BeginColBox()
```julia;eval=false
fittedpoly = fit(LagrangePoly, x, y)
```
! EndColBox()

Crucially however, we also make use of multiple dispatch to dispatch on a function arguments, allowing the user to define a function to fit, rather than merely data points.
! BeginColBox()
```julia;eval=false
fittedpoly = fit( (x) -> x^2 - 5, 7)
```
! EndColBox()
As no data point spacing has been specified (only the number of points), we can also guess that the user might wish to use an LGR spacing, as this provides a good approximation when using Lagrange polynomials.
This is not consistent with the arguments that Polynomials.jl fit command takes, but it is consistent with the intent of the user.
The user knows what it means to fit a polynomial to a function, and so this formulation is intuitive from a human perspective.
We employ similar patterns in our speech every day.
One can say "I am going to work" or "I am going to Spain" or "I am going to walk the dog".
All these actions are conducted in different manners, but the intent of the statement is the same, that one will travel from one place to another through some means.
Here, we take ``fit()`` to mean fit some input to a polynomial representation, the internals are dependent on the context.
As the core role of the programming language is to provide an interface between the human and the computer it makes sense (when we have the ability) to tailor the experience in a way similar to how a human would behave.

An extension of the user interface is the ability to handle errors elegantly.
Good error reporting is a balance between providing the used with useful information to debug the error, while not overloading the user with too much information.
Generally the author believes it is better to provide too much information than too little.
Examples of detailed error reporting can be found when using the `GlobalPoly` polynomial type.
For example, if we try evaluating a value that does not exist in any of the subpolynomial domains, we get the following error
! BeginColBox()
```julia;results=hidden
p = LGRPoly([1.0, 2, 1])
piecewisePoly = GlobalPoly(p, 0, 1)
push!(piecewisePoly, p, 2, 3) # polynomial defined over [0,1] and [2,3]
piecewisePoly(1.7)
```
! EndColBox()
Here we are not only told what the error is, but we're provided information which may help give us a better idea of where we're going wrong.
Another example would be when trying to add a polynomial to a continuous piecewise polynomial which would violate the continuity.
In this case, the endpoints of the 2 lines generated here do not line up
! BeginColBox()
```julia;results=hidden
x1 = LagrangePoly([0.0, 1], [1.0, 3])
x2 = LagrangePoly([0.0, 1], [2.0, 4])
piecewisePoly = GlobalPoly(x1, 0, 1)
push!(piecewisePoly, x2, 1, 2) 
```
! EndColBox()
Once again we are told exactly what went wrong, and how we might go about fixing it.
Contextual data driven errors can be a very useful tool for debugging and especially so when complex problems such as dynamic optimisation problems are being debugged.



## JuDO.jl
The development of the JuDO.jl package has been somewhat more staggered than the MorePolynomials.jl package.
While MorePolynomials.jl inherits much of the design ethos from Polynomials.jl, JuDO.jl has no such counterpart.
Additionally, one of the key learning points from ICLOCS was that a good base design facilitates easy and intuitive feature addition, and avoids problems associated with feature creep.
As such, progress with JuDO.jl has been slow but deliberate.
In this text we will outline a basic generic implementation of transcription methods in JuMP.jl, and a proposed architecture to be taken forward based on the project aims.

### Generic transcription implementation
A transcription method which employs the use of user defined functions has been implemented in Julia using the JuDO.jl package with the Ipopt NLP solver.
The key innovation here is the formatting of the problem such that the user can define any generic functions for the objective function, constraints and dynamics and, providing the functions accept a standard input and output, the solver behave as expected.

The user defined problem, which also acts as an internal interface between JuMP.jl and JuDO.jl methods, is defined as follows.
! BeginColBox()
```julia;eval=false
mutable struct TrajProblem
    objectiveFunc::Function
    dynamicsFunc::Function
    pathConstraintFunc::Function
    controlVector::Array
    stateVector::Array # each row represents a state, maybe use an add state guess function which adds each state guess
    timeStep::Union{Array, Float64} 
    boundaryConstraints::BoundaryConstraint 
    numStates::Int   
    numControls::Int
    numCollocationPoints::Int 
end
```
! EndColBox()

JuMP.jl provides its own interface for defining functions with derivatives, the trick is formatting the interface in such a way as to work with dynamic optimisation problems.
This is accomplished using three components, a global `CurrentProblem` type, a translating layer and a derivative function.

First, the global `CurrentProblem` type allows us to access the full problem definition from any location within our program. 
This is useful as it provides a standard interface which we can access within functions, which we can used to access crucial data such as they problem functions and state and control interpolation functions.
Moreover, the user defined functions in JuMP.jl only allow the parsing of JuMP.jl variables internally, so to have access to any additional data defined externally one must define such an interfaces as this.
Within the JuDO.jl code this `CurrentProblem` type  is defined as a global constant, which acts like a pointer to the location of the user defined `TrajProblem`.
The interface is defined below.
! BeginColBox()
```julia;eval=false
mutable struct CurrentProblem
    nullableProblem::Union{TrajProblem,Nothing}
end
const CURRENT_PROBLEM = CurrentProblem(nothing)
setCurrentProblem(problem::TrajProblem) = (CURRENT_PROBLEM.nullableProblem = problem)
getCurrentProblem() = CURRENT_PROBLEM.nullableProblem
```
! EndColBox()

Now the translational layer provides a set of functions for translating between the JuMP.jl user defined functions, and our own custom functions and collocation methods.
Their implementation primarily consists of translating 1D decision variable vectors from JuMP.jl into 2D state and control vectors, and then back to 1D vectors for JuMP.jl.
Additionally, JuMP.jl do not provide a robust method for determining what decision variable we're focusing on within a user defined function, so additional interfaces for state and control indexing are provided by this layer.

Finally, for each user defined function we provide for JuMP.jl, we must additionally provide the derivative information.
This is done using the ForwardDiff.jl package which provides forward mode automatic differentiation for Julia functions, which can be used to calculate the Jacobian and Hessian arrays.
ForwardDiff.jl achieves this by injecting the function with a custom type which has union with the `Real` type, which has the limitation of requiring all internal operations to be compatible with the real type.
If this is not the case however a forward difference method may be implemented in its place.
The differentiation functions work by calculating the fully Jacobian and then returning the row associated with the state or control in question.
For example, in the case of the cart-pole example in section ``\ref{cartpolesec}`` below, we can calculate the Jacobian using command.
```julia;echo=false; results="hidden"

function dynamicsFunc(stateVector, controlVector) 
    l = 0.5
    m1 = 1
    m2 = 0.3
    g = 9.81
    x2 = stateVector[2,:]
    u = controlVector[1,:]
    x1dot = stateVector[3,:]  
    x2dot = stateVector[4,:]
    x3dot = map((x2, x2d,u) -> (l * m2 * sin(x2)*x2d^2 + u + m2 * g * cos(x2)*sin(x2) )/ (m1 + m2 *(1 - cos(x2)^2)), x2, x2dot, u)
    x4dot = map( (x2,x2d,u) -> - (l*m2*cos(x2)*sin(x2)*x2d^2+u*cos(x2)+(m1+m2)*g*sin(x2)) / (l*m1+l*m2*(1-cos(x2)^2)) , x2, x2dot, u)
    return [x1dot';x2dot';x3dot';x4dot']
end
function collocateConstraint(stateControlVector::Array) # make sure timestep vector matches length of state vector
    # assemble state and control vector from tuple inputs
    stateVector, controlVector = getXUFromStateControl(stateControlVector)

    ΔstateVector = 0.5 .*  0.0689655.* (dynamicsFunc(stateVector[:,2:end], controlVector[:,2:end]) + dynamicsFunc(stateVector[:,1:end-1], controlVector[:,1:end-1])) # how do we ensure dynamicsFunc has the right inputs and outputs if it is user defined? also have a look at making timestep dynamic for each value
    ζ = stateVector[:, 2:end] - stateVector[:,1:end-1] - ΔstateVector
    return ζ
end

function getXUFromStateControl(stateControlVector::Array) # get separate state and control vector matricies from input tuple
    stateVector = Array{Union{Missing, typeof(stateControlVector[1]) }}(missing, 4, 30)
    controlVector = Array{Union{Missing,typeof(stateControlVector[1]) }}(missing, 1, 30)
    stateVector[:,:] = stateControlVector[1:4, :]
    controlVector[:,:] = stateControlVector[4 + 1, :]
    return stateVector, controlVector
end

numCP = 30
T = 2
controlVector = zeros(1,numCP)
timeStep = ones(1,numCP-1) * T/(numCP-1)
time = pushfirst!(cumsum(timeStep';dims=1)[:,1],0.0)
stateVector = [1 π 0 0]' * time'  /T
```

! BeginColBox()
```julia
jacobian = ForwardDiff.jacobian(collocateConstraint, [stateVector; controlVector])
```
! EndColBox()
Take note of the sparsity pattern here.
Julia has methods for handling sparse matrices, and one of the future goals of the project is to support sparse matrix represents for derivatives.
If we are looking for the derivatives of the first state (or more correctly in this case the first collocation function) relative to perturbations in the other states, we can take the first row of this Jacobian.
! BeginColBox()
```julia
df1dt = jacobian[1,:]'
```
! EndColBox()


Now that we have the core components to interface with JuMP.jl, the rest is a matter of formulating the JuMP.jl NLP problem and solving. 
Links to the full implementation can be found in the appendix.

### Example cart-pole swing-up
! Label("cartpolesec")
An example implementation is the cart-pole swing-up problem, where the objective is to swing a mass above a cart using the minimum effort squared.
The example is taken from Matthew Kelly's paper ``\cite{Kelly2017AnCollocation}`` and has the following formulation
$$
\pmb{x}(t) = 
\begin{bmatrix}
q\\
\theta\\
\dot{q}\\
\dot{\theta}

\end{bmatrix} 
= 
\begin{bmatrix}
\pmb{x}_1(t)\\
\pmb{x}_2(t)\\
\pmb{x}_3(t)\\
\pmb{x}_4(t)
\end{bmatrix},
$$
$$
\pmb{f}(\tau, \pmb{x},\pmb{u}) = 
\begin{bmatrix}
\dot{q}\\
\dot{\theta}\\
\ddot{q}\\
\ddot{\theta}
\end{bmatrix}
= 
\begin{bmatrix}
\pmb{x}_3\\
\pmb{x}_4\\
\frac{lm_2\sin(\pmb{x}_2)\pmb{x}_4^2 + \pmb{u}_1 + m_2g\cos(\pmb{x}_2)\sin(\pmb{x}_2)}{m_1+m_2(1-\cos^2(\pmb{x}_2))}\\
- \frac{lm_2\cos(\pmb{x}_2)\sin(\pmb{x}_2)\pmb{x}_4^2 + \pmb{u}_1\cos(\pmb{x}_2) + g(m_1 + m_2)\sin(\pmb{x}_2)}{lm_1+lm_2(1-\cos^2(\pmb{x}_2))}
\end{bmatrix}_{\tau},
$$
$$
J(\pmb{u}) = \int_0^{t_F} \pmb{u}^2_1(t)dt,
$$
$$
\begin{align*}
\pmb{x}_1(t_1) = 0, & \quad  \pmb{x}_1(t_F) = 1, \\
\pmb{x}_2(t_1) = 0, & \quad  \pmb{x}_2(t_F) = \pi,\\
\pmb{x}_3(t_1) = 0, & \quad  \pmb{x}_3(t_F) = 0,\\
\pmb{x}_4(t_1) = 0, & \quad  \pmb{x}_4(t_F) = 0,\\
\end{align*}
$$
$$
-2 \leq \pmb{x}_1(t) \leq 2, \quad -20 \leq \pmb{u}_1(t) \leq 20,
$$
$$
\pmb{x} \in \mathbb{R}^4, \quad \pmb{u}_1 \in \mathbb{R}
$$

where ``q`` is the cart position, ``\theta`` is the pole angle, ``\pmb{u}_1`` is the force applied horizontally to the cart, ``m_1`` is the mass of the cart, ``m_2`` is the mass at the end of the pole, ``g`` is standard acceleration due to gravity and ``l`` is the length of the pole.

Within our code, we begin by constructing the problem definition which will be parsed to the solver.
! BeginColBox()
```julia;eval=false
numCP = 30
tf = 2
timeStep = ones(1,numCP-1) * tf / (numCP-1)
time = pushfirst!(cumsum(timeStep';dims=1)[:,1],0.0)
controlVectorGuess = zeros(1,numCP)
stateVectorGuess = [1 π 0 0]' * time' / tf
boundaryConstraints = BoundaryConstraint([0;0;0;0],[1;π;0;0])

# create user defined problem
problem = TrajProblem(objectiveFunc, dynamicsFunc, pathConstraintFunc, controlVectorGuess, stateVectorGuess, timeStep, boundaryConstraints, 4, 1, numCP)
```
! EndColBox()
We're using 30 collocation points here, and we assume the state and control mesh points correspond exactly with the collocation points.
Additionally, we also define an initial guess for state and control.

Next, we define custom functions for the dynamics, the objective function and path constraints.
! BeginColBox()
```julia;eval=false
function dynamicsFunc(stateVector, controlVector) 
    l = 0.5
    m1 = 1
    m2 = 0.3
    g = 9.81
    x2 = stateVector[2,:]
    u = controlVector[1,:]
    x1dot = stateVector[3,:]  
    x2dot = stateVector[4,:]
    x3dot = map((x2, x2d,u) -> (l * m2 * sin(x2)*x2d^2 + u + m2 * g * cos(x2)*sin(x2) )/ (m1 + m2 *(1 - cos(x2)^2)), x2, x2dot, u)
    x4dot = map( (x2,x2d,u) -> - (l*m2*cos(x2)*sin(x2)*x2d^2+u*cos(x2)+(m1+m2)*g*sin(x2)) / (l*m1+l*m2*(1-cos(x2)^2)) , x2, x2dot, u)
    return [x1dot';x2dot';x3dot';x4dot']
end

objectiveFunc(stateVector, controlVector) = controlVector.^2

function pathConstraintFunc(stateVector, controlVector) # less than or equal to output value. Output must by 1 D vector of constraints
    dmax = 2
    umax = 20
    bounds = zeros(typeof(stateVector[1,1]),4,size(stateVector,2))
    bounds[1,:] = -dmax .- stateVector[1,:]
    bounds[2,:] = -dmax .+ stateVector[1,:]
    bounds[3,:] = -umax .- controlVector[1,:]
    bounds[4,:] = -umax .+ controlVector[1,:]
    return [bounds...]
end
```
! EndColBox()
In this formulation we are not yet considering interpolated functions, but this is of little consequence if we're using trapezoidal collocation, as we will be here.
The disadvantage of this is that in our function formulation we have to keep in mind the array nature of our states and controls, something present in the ICLOCS package too.

Finally we define the methods for collocation and interpolations.
! BeginColBox()
```julia;eval=false
function collocateConstraint(state::Array, control::Array) 
    ΔstateVector = 0.5 .* problem.timeStep[1] .* (problem.dynamicsFunc(stateVector[:,2:end], controlVector[:,2:end]) + problem.dynamicsFunc(stateVector[:,1:end-1], controlVector[:,1:end-1])) 
    ζ = stateVector[:, 2:end] - stateVector[:,1:end-1] - ΔstateVector
    return ζ
end

function objectiveFuncInterp(state::Array, control::Array)  # can we type union this? so we don't have to define two functions, only one
    # return interpolated integral
    return [sum(0.5 .* problem.timeStep[1] .* (problem.objectiveFunc(stateVector[2:end,:], controlVector[2:end]) .+ problem.objectiveFunc(stateVector[1:end-1,:], controlVector[1:end-1])))] 
end
```
! EndColBox()
The exact implementation within the code is slightly different due to some additional translation code for JuMP.jl as described above, but this code could nonetheless be implemented in its shown form with some wrapper functions.
The results of the solve are found below.

! BeginFig()
```julia; out_width="0.7\\textwidth";echo=false
img = load("figures/cartepole.png")

```
! EndFig("Cart-pole optimisation results using JuMP.jl/JuDO.jl","cartpolefig")

### Example pseudospectral method

The current JuDO.jl code can be altered to accept interpolating functions generated by MorePolynomials.jl.
We will use an example problem from a paper by Garg ``\cite{Garg2011DirectMethod}`` to demonstrate this.
$$
J(\pmb{x},\pmb{u}) = \frac{1}{2} \int_0^{t_F} (\pmb{x}_1(t) + \pmb{u}_1^2(t))dt, \quad \dot{\pmb{x}}_1(t) = 2\pmb{x}_1(t) + 2\pmb{u}_1(t) \sqrt{\pmb{x}(t)}
$$
$$
\pmb{x}_1(0) = 2, \quad \pmb{x}_1(t_F) = 1, \quad t_F = 5.
$$

The problem formulation is now as follows.
! BeginColBox()
```julia;eval=false
using MorePolynomials

numCP = 39
lgrPoints = lgr_points(numCP)
x = LagrangePoly([lgrPoints...,1],ones(numCP+1)) # state
u = LGRPoly(ones(numCP)) # control
boundaryConstraints = BoundaryConstraint([2],[1])
problem = TrajProblem(x, u, derivative(x),derivmatrix(x), boundaryConstraints,[lgrPoints...,1],1,1,lgr_weights(u))
```
! EndColBox()
Note we now include a derivative matrix in our formulation.
The advantage of using fixed Lagrange mesh points is that new derivatives can be calculated by a simple matrix multiplication as per equation ``\ref{Ldot}``.
We also provide a polynomial to represent the state derivative.
Internally, we now collocate the state using equation ``\ref{psecoloc}``
! BeginColBox()
```julia;eval=false
function collocateConstraint(k, stateVector...)
    problem.x[:] = stateVector
    return problem.xdot(τ[ζr]) - problem.dynamicsFunc(τ[ζr], problem.x, problem.u)
end
```
! EndColBox()
where `k` is a reference to the index of the collocation point.
Note here we treat `ydot()` as an interpolating function, rather than indexing into an array as per the cart pole example.
Thus we fulfil aim ``\ref{indepmeshaim}``.
The results of the optimisation are in figure ``\ref{psufig}``.
! BeginFig()
```julia; out_width="0.7\\textwidth";echo=false
img = load("figures/lgrplot.png")
```
! EndFig("Pseudospectral example solution","psufig")


# Next Steps
## JuDO.jl architecture
An architectural outline for JuDO.jl is proposed in figure ``\ref{judoarc}``.
The generic implementation prototype already employs some of the features here, but not to the full extent.
The methodology behind the architecture is outlined below, and the methods proposed for how to implement each component, based on experience with ICLOCS and Julia.
! BeginFig()
```julia; out_width="0.7\\textwidth";echo=false
img = load("figures/judo.png")
```
! EndFig("JuDO.jl architecture","judoarc")

The architecture has eight components, five of which are referred to as factories.
It is proposed that, to facilitate aim ``\ref{aimmodular}``, the package should be broken up into individual factories, each of which act as an autonomous agent, with a set of standard interfaces and definitions of the problem.
This interface is the JuDO problem type itself, which is parsed between factories.
The role of the factory is to manage one component of the problem and provide an expected output.
For example, the role of the derivate factory is to handle all derivative production within JuDO.jl.
Additionally, using multiple dispatch we can dispatch on various problem formulations within each factory and, providing the interface is standardised for a particular problem formulation, there should be minimal developer headache.
We may also dispatch on particular solvers if they support a particular feature which may be exploited internally.
For example a black box solver does not require derivative information, and so the derivative factory would dispatch and return nothing accordingly.
This factory architecture is also useful from a development perspective.
Multiple developers can work on different factories within JuDO.jl while being confident that their interface will integrate well with the rest of the solver.

### User defined problem
The aim here is to provide a standard intuitive interface for problem definitions which requires as little knowledge of the backend implementation as possible.
Ideally the user would define their problem as seen in the mathematical formulation. 
There should be little need to try and reformulate the problem in order to work with matrix operations or specific functions.
We can leverage Julia macros to reformulate dynamics functions in a format understandable by our solver.
For parameters such as solver selection, it is suggested that custom types should be used, such as `struct Ipopt <: AbstractSolver end`, as an example.
For states and controls, a Julia symbol is used.
The following user defined problem syntax is suggested.

! BeginColBox()
```julia;eval=false
problem = new_JuDO_problem()
solver(problem,SolverType)
addstate(problem, :x)
addcontrol(problem, :u)
addparameter(problem, :p, val)
xdot = @JuDOFunc function xdotfunc(p,τ)
            xdot = f(x(τ), u(τ), p) 
            return xdot
       end
adddynamicsfunction(problem, :x, xdot) # an example function is used here
constrain = @JuDOFunc function constrainfunc(p, τ)
            constrain = h(x(τ), u(τ), p)
            return constrain >= 0
       end
addboundsfunction(problem, :x, xdot) # an example function is used here
```
! EndColBox()

### JuDO problem
The role of the JuDO problem is to act as an internal standard interface between all other factories.
Internally, it is represented by a data structure containing all relevant components of the problem.
Each factory either modifies or uses data from the JuDO problem.
Additionally, components within the JuDO problem may have their own structures.
An example is the `AbstractState` which may contain a vector of Lagrange interpolating polynomials, as an example.
This abstraction allows us to generate standard interfaces for each data component, ensuring future compatibility is part of the structure changes form (if we used a package other than MorePolynomials.jl for example).
The following data structure is suggested.

! BeginColBox()
```julia;eval=false
mutable struct JuDOProblem <: AbstractJuDOProblem
    x::AbstractState
    u::AbstractControl
    dynamics::AbstractDynamics
    constraints::AbstractConstraint
    objective::AbstractObjective
    solver::AbstractSolver
    results::AbstractResults
end
```
! EndColBox()

### Solver translator
Different solvers will have different interfaces, and while we could dispatch on each solver, this incurs a significant amount of code rewriting for each solver.
A more elegant solution would be to standardise the interface between each solver by using a layer of abstraction.
This requires only the rewriting of a few translation functions per solver, rather than changing the entire system architecture, and is the preferred implementation method.

### Mesh factory
The role of the meshing factory is to generate meshes based on the user defined problem, and refine meshes after successful solves.
The user can either specify what type of mesh they would like, or we can generate one for them based on the problem definition.
The following function definition is proposed for the mesh factory.
! BeginColBox()
```julia;eval=false
function mesh_factory(solver::AbstractSolver, udp::AbstractUserDefinedProblem) # initial problem formulation
    #...
    return JuDO_problem
end
function mesh_factory(solver::AbstractSolver, problem::AbstractJuDOProblem) # Mesh refinement
```
! EndColBox()
### Function factory
The aim of the function factory is to provide a standard interface for handling functions, such that various transcription methods can be employed.
Additionally, a standard interface will ensure compatibility with derivative calculation in the derivative factory.
The following function definition is proposed for the function factory.
! BeginColBox()
```julia;eval=false
function function_factory(problem::AbstractJuDOProblem,; kwargs...)
    #...
    return problem
end
function function_factory(problem::AbstractJuDOProblem, solver::AbstractSolver; kwargs...) # custom solver implementation
function dynamics_transcription(problem::AbstractJuDOProblem, dynamicsFunction::Function, method::AbstractTranscriptionMethod) # system dynamics transcription
function objective_function(problem::AbstractJuDOProblem) 
function constraints_function(problem::AbstractJuDOProblem) 
```
! EndColBox()
It is important to note that although we provide an interface for dispatching on the solver, the intention is to use this sparingly when implementing a feature specific to the solver.
The majority of solver specific actions should be taken in the solver translator layer.
Note also that each factory is not necessarily an object as in a traditional OOP program, but rather a collection of functions. 
This has the added benefit that these functions can be called by other functions.
For example, it is useful in this case for the derivative factory to call some functions within the function factory to calculate derivatives.

### Derivative factory
The derivative factory calculates the derivatives of NLP functions to parse to the NLP solver.
The aim here is to support multiple derivative methods, as well as sparsity patterns.
Because of the standard JuDO problem interface, we can deduce from within the problem what the parameters to dispatch on for the function factory function calls should be.
The following function definition is proposed for the derivative factory.
! BeginColBox()
```julia;eval=false
function derivative_factory(problem::AbstractJuDOProblem; kwargs...)
    #...
    return problem
end
function derivative_factory(problem::AbstractJuDOProblem, solver::AbstractSolver) # custom solver implementation
function jacobian(problem::AbstractJuDOProblem) 
function hessian(problem::AbstractJuDOProblem) 
```
! EndColBox()

### Error factory
The role of the error factory is to handle any errors from the solver elegantly in a standardised manner, and to manage the analysis of errors.
The error analysis can then be packaged and sent to the mesh factory for further mesh refinement.
The following function definition is proposed for the error factory.
! BeginColBox()
```julia;eval=false
function error_factory(problem::AbstractJuDOProblem; kwargs...)
    #...
    return problem
end
function error_factory(problem::AbstractJuDOProblem, solver::AbstractSolver) # custom solver implementation
function calculate_error(problem::AbstractJuDOProblem)
```
! EndColBox()

### Output factory
The role of the output factory is to display the results of the optimisation problem, and proved interfaces for the user to save the problem.
We can do this by taking the solved problem as well as the error analysis and presenting it to the user.
The output factory should ideally handle any interactions with the user, including solver errors produced by the error factory.
The following function definition is proposed for the output factory.
! BeginColBox()
```julia;eval=false
function output_factory(problem::AbstractJuDOProblem; kwargs...)
    #...
    return problem
end
function print_output(problem::AbstractJuDOProblem)
function plot_output(problem::AbstractJuDOProblem)
function save_output(problem::AbstractJuDOProblem)
```
! EndColBox()

# Conclusions
In this work have outlined a method for implementing a generic dynamic optimisation problem in Julia with the use of interpolating polynomials.
We have achieved this through the development of two autonomous Julia packages, one for polynomial interpolation, and one for transcribing dynamic optimisation problems and interfacing with nonlinear programming solvers.
We have shown how barycentric interpolation and effective utilise of Julia features can significantly reduce overhead in our problem associated with the generation and interpolation of polynomials.
Lastly, we have outlined the framework for a generic and developer friendly optimal control package based on the experiences of using JuMP.jl and ICLOCS.
! Newpage()

! Bib()

! Newpage()

! BeginAppendix()

# Package code
## MorePolynomials.jl
The code for MorePolynomials.jl can be found at 

`https://github.com/sprockmonty/MorePolynomials.jl`.
## JuDO.jl
The code for JuDO.jl can be found at 

`https://github.com/sprockmonty/JuliaFYP`.
# Julia Thesis
The code for this thesis as implementer in Julia can be found at 

`https://github.com/sprockmonty/JuliaOptimisationThesis`.

! EndAppendix()
