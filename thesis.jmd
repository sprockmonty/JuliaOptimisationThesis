---
title : Dynamic Optimisation using the Julia Programming Language
author : Nathan Davey
options :
    template : julia_tex.tpl
---

```julia; echo=false
using Images, Plots, Colors

struct Begin
    text
end

struct End
    text
end

Base.show(io::IO, m::MIME"text/latex", b::Begin) = write(io, "\\begin{$(b.text)}\n ")
Base.show(io::IO, m::MIME"text/latex", e::End) = write(io, "\\end{$(e.text)}\n")

struct Newpage end
Base.show(io::IO, m::MIME"text/latex", n::Newpage) = write(io, "\\newpage\n ")

struct NomItem
    symbol
    text
end
Base.show(io::IO, m::MIME"text/latex", n::NomItem) = write(io, "\\nomenclature{\$ $(n.symbol) \$}{$(n.text)}\n ")

struct NomPrint end
Base.show(io::IO, m::MIME"text/latex", n::NomPrint) = write(io, "\\printnomenclature\n ")

struct BeginFig end

struct EndFig
    cap
    label
end
Base.show(io::IO, m::MIME"text/latex", b::BeginFig) = write(io, "\\begin{figure}[h]\n\\centering\n ")
Base.show(io::IO, m::MIME"text/latex", e::EndFig) = write(io, "\\caption{$(e.cap)}\\label{$(e.label)}\n\\end{figure}\n")

struct Label
    text
end
Base.show(io::IO, m::MIME"text/latex", l::Label) = write(io, "\\label{$(l.text)}\n")


struct Table
    cap
    label
    tableArray::Array
end

function Base.show(io::IO, m::MIME"text/latex", t::Table) 
    
    write(io, "\\begin{table}[h]\\label{$(t.label)}\\centering\n")
    ls = "l"
    r = size(t.tableArray)[1]
    c = size(t.tableArray)[2]
    for i = 1:c-1
        ls = ls*"l"
    end
    write(io, "\\begin{tabular}{$ls}\n")
    for i = 1:r
    out = ""
        for j = 1:c
            if j == c
               out = out * string(t.tableArray[i,j])* "\\\\" 
            else
               out = out * string(t.tableArray[i,j])* "&" 
            end
        end
        if i==1
            out = out * " \\hline  \n"
        else
            out = out * "\n"
        end
    write(io, out)
    end
    write(io, "\\end{tabular}\\caption{$(t.cap)}\n")
    write(io, "\\end{table}\n")
end

``` 
! Begin("abstract")

Some abstract

! End("abstract")

! Newpage()

! NomItem("J","Objective function")
! NomItem("\\pmb{g}","Constraint functions")
! NomItem("\\pmb{f}","System dynamics functions")
! NomItem("\\pmb{x}","States")
! NomItem("\\pmb{u}","Controls")
! NomItem("\\pmb{b}","Boundary constraint functions")
! NomItem("\\pmb{h}","Path constraint functions")
! NomItem("t","Time")
! NomItem("k","Location of a collocation point")
! NomItem("N","Total number of collocation points")


! NomPrint()

! Newpage()

# Introduction

## Motivation

### Dynamic Optimisation
Optimisation problems are the focus of wide range of research fields, and have broad applications to almost any discipline.
As such, effective tools for solving optimal problems are extremely desirable, and are employed in fields such as medicine, robotics and aerospace.
Specifically, optimal problem solvers allow us to streamline the design an operation of, for example, a reusable spacecraft, or a walking robot, or the layout of a hospital.
If the problem has a cost function and can be formulated subject to certain mathematical constraints, it can be optimised.
<!-- add some history here init -->
Dynamic optimisation is a subset of general optimisation problems, where the problem is best thought of as finding the optimal control input that minimises some cost function through statespace subject to system dynamics and constraints. 
An example would be finding the optimal thrust output over time from the earth to another body which maximises the final orbital radius (as seen in ``\cite{Bryson}``). 
<!-- add ref at bottom of page here http://www.ee.ic.ac.uk/ICLOCS/ExampleOrbitRaising.html -->

Dynamic optimisation problems can be solved by the process of transcription.
Transcription is the process of translating a continuous control problem into a discrete nonlinear programming problem (NLP) which can then be solved by an NLP solver.
A general formulation of the dynamic optimisation problem can be found in section ``\ref{dynamicsmath}``.


The focus of this project is thus to lay the foundations for a simple but powerful dynamic optimisation toolbox, such that users can spend more time on the problem formulation and results without needing a detailed background in optimisation.
As history has shown, more can be achieved when time is spent letting the tools work on the problem rather than trying to make the problem work with the tools.

### Imperial College London Optimal Control Software (ICLOCS)

### Julia
The Julia programming language is a product of the desire to have highly performant code in a dynamic, high level format i.e. having your cake and eating it.
Julia has been designed with numerical analysis and computational science in mind ``\cite{juliawhite}``, and aims to solve what is referred to as the two language problem.
The two language problem is that, with the advent of rapid prototyping languages such as python and MATLAB, code can be written and tested quickly at the cost of scalability.
Once the code has been written, core components are translated into a low level but performant languages, e.g. C/C++ or Rust.
Julia bridges the gap by having easy to read and prototype code which is performant and even garbage collected.
This is achieved by a well thought out architecture and a clever just-in-time (JIT) compiler ``\cite{juliawhite}``.
While code must still be written with a certain level of awareness of lower level processes and implementations, and as such a certain style of programming must be adopted to achieve truly performant code, the main goals of Julia are delivered on to a more than satisfactory level.
The gains from Julia by solving this problem is more than just faster transition to production.
The ability to have performant, high level code can increase the shareability and modularity of code. 
For programs written natively in Julia, (providing the source code is easily accessible), users wishing to understand and adapt code packages no longer have to trace through difficult to understand C++ programs and try and guess which parts of code exist purely to speed up performance.

Although Julia takes heavy inspiration from other languages such as C, MATLAB. Python and Lisp (to name a few), through the implementations of its main paradigm it holds its own in the world of dynamic general programming languages.
By choosing to diverge from the commonly practiced object oriented programming (OOP) paradigm, Julia presents an alternative and more intuitive interface using multiple dispatch and strong type interfaces.

What is very apparent in Julia is that every line of code has been scrutinised, and each feature thought about to great depth.
The effect of this is that code feels like it makes sense, rather than a group of features bundled together into a programming language (see: PHP).
In addition, Julia is a general purpose language.
So general purpose that this very document has been typeset using Julia.
The advantage of this is the ability to apply Julia variety of applications.
If all the user wishes to do is simulate a spacecraft in orbit (for example), this benefit is of little consequence.
But say the user now wants a live visualisation of the spacecraft.
If there already exists a general purpose visualisation package in Julia, hours can be saved from having to develop an interface between your code and the outside world.




# Mathematical Background
## Dynamic optimisation problem formulation
! Label("dynamicsmath")
Here we will outline the basic formulation of the dynamic optimisation problem.
It is important to note that the main objective of dynamic optimisation is to find a set of optimal control inputs which results in the boundary constraints and system dynamics being satisfied, and a minimisation of the objective function.
As such, we can break down the problem into 3 main components:

```julia; echo=false
problemComponents = ["System dynamics",
                     "Boundary and path constraints",
                     "Objective function"];
```

1) `j print(problemComponents[1])`
2) `j print(problemComponents[2])`
3) `j print(problemComponents[3])`
<!-- Illustrate this with a flow chart -->
The following discussion assumes the direct method i.e. transcription.
Transcription is the process of converting a continuous dynamic optimisation problem into an array of discrete constraints (which ensure system dynamics are consistent with the state as explained in section ``\ref{sysDyn}``) which can be solved by a nonlinear programming (NLP) solver.
The direct methods are, well, direct, because we just try and solve the problem by breaking it up into smaller constraint equations.
Indirect methods, on the other hand, solve the problem by reformulating (analytically) the problem using a set of first-order necessary conditions for optimality, which can then be solved.
Direct methods are currently of more interest as these conditions are often difficult to formulate, and indirect methods are more sensitive to the accuracy of the initial state guess ``\cite{mit}``.
Before we explore the direct method however, it may be beneficial to define what our dynamic optimisation problem will eventually become, a nonlinear programming problem.

### Nonlinear programming problem
If we can reformulate our dynamic problem into a NLP problem, we can use a number of widely available solvers to find optimal solutions.
The general formulation of the NLP problem is (as given by Ipopt from COIN-OR ``\ref{ipopt}``, a popular NLP solver)

$$
\begin{align}
\min_{x\in\mathbb{R}^n} & \quad J(\pmb{x}) \\
\text{s.t.} & \quad \pmb{g}^L \leq \pmb{g}(\pmb{x}) \leq \pmb{g}^U \label{gineq}\\
& \quad \pmb{x}^L \leq \pmb{x} \leq \pmb{x}^U \label{xineq}
\end{align}
$$

Where
$$
J : \mathbb{R}^n \rightarrow \mathbb{R}
$$

is the objective function to be minimised, and

$$
g : \mathbb{R}^n \rightarrow \mathbb{R}^m 
$$

are functions that represent nonlinear constraints.
In this text we use bold font to denote the existance of an array of either variables or functions.
In this particular case, ``\pmb{g}`` comprises of multiple constraint functions with multiple inputs and outputs.
The nonlinear constraint may also take the form (which is more common in the syntactic formulation of dynamic optimisation problems)
$$
\begin{equation}
\label{gfunc}
\pmb{g}(\pmb{x}) \leq 0
\end{equation}
$$
Solvers such as Ipopt additionally replace nonlinear inequality constrains with an equality constraint and a slack variable ``\cite{ipopttut}`` such that equation ``\ref{gineq}`` becomes ``\pmb{g}(\pmb{x}) - s = 0`` and ``\pmb{g}^L \leq s \leq \pmb{g}^U``. 
As such it makes sense to also include in our formulation the additional equality constriants
$$
\begin{equation}
\label{gfunceq}
\pmb{g}(\pmb{x}) = 0
\end{equation}
$$

The nonlinear constraints may take the form of either equation ``\ref{gfunc}`` or ``\ref{gfunceq}``, or both.

The target of dynamic optimisation is to discretize the dynamic optimisation problem into a set of constrained points (known as collocation points) which can be expressed as a series of dynamics constraints and solved as a nonlinear problem.
The forces that govern the system thus become a discretized set of equality constraints that essentially say the system must behave in this way otherwise the physics would be violated.
Another way to put it is rather than giving an input and calculating what the output would be based on extrapolation of the system dynamics through time marching (such as in a shooting method), we evaluate what the physics would have to be at each location in time to satisfy a given input.
<!-- Illustrate this with some diagrams -->

We will now go on to explore how the dynamics optimisation problem becomes the NLP problem.

### `j print(problemComponents[1])`

The system dynamics are of key importance in the dynamic optimisation problem, and are what essentially separate it from a standard NLP problem.
By system dynmaics, we are referring to the governing equations which describe the evolution of the state over time.
Simply put, if ``\pmb{x}`` is our state, ``\pmb{u}`` is our control input and ``t`` represents time we have

$$
\begin{equation}
\frac{\partial \pmb{x}}{\partial t}\rvert_{t_k} = \dot{\pmb{x}}\rvert_{t_k} = \pmb{f}(\pmb{x},\pmb{u})\rvert_{t_k}
\end{equation}
$$

Essentially we are saying the change of state through time (derivative) is a function of both the state(s) and control(s) at that instance in time. 

Let's define our terms a little more thoroughly.
Our state is denoted by ``\pmb{x}``, which in reality represents a vector of states such that

$$
\bar{x} \in \mathbb{R}^m
$$

Where ``m`` here is the number state discritzation points, otherwise known as mesh points.
This is not to be confused with the number of collocation points, which is most cases is the same but in some is different.
Collocation points are the points where system dynamics are enforced, but not all points where we approximate state have to comply with system dynamics.
Also note we use the overbar in ``\bar{x}`` to represent a vector of mesh points such that ``\bar{x}_{ik} = x_i(t_k)``, where ``x_i(t_k)`` it the ``i^{\text{th}}`` state evaluated at time ``t_k``.

If the number of mesh points is the same for each state it may be convenient to define ``\pmb{x}`` as 

$$
\pmb{x} \in \mathbb{R}^{n \times m}
$$

Where ``n`` is the number of states (e.g. distance, velocity etc. ). 
In some cases (if the toolbox supports such a formulation) we may require each individual state to have a different mesh size.
If this is the case, we can define ``\pmb{x}`` as 

$$
\begin{equation}
\label{xState}
\pmb{x} = \bar{x_i} \in \mathbb{R}^{m_i}, \quad i = 1,2 \ldots n
\end{equation}
$$

Such that ``m \in \mathbb{R}^n`` may contain a different value at each state index ``i``.
Supporting this formulation is indeed one of the aims of the toolbox being developed here and as such this shall be the assumed notation from now on.

Likewise we may use the same definition for our control variables.
$$
\begin{equation}
\label{uControl}
\pmb{u} = \bar{u_i} \in \mathbb{R}^{m_i}, \quad i = 1,2 \ldots c
\end{equation}
$$

Where ``c`` is the number of controls. The state can control points as formulated here are decision variables in our NLP problem, that will be varied by the solver in order to find the optimal solution.

Our system dynamics function is how we specify the dynamics (in many cases physics) of the system being optimised, and is represented as an array of functions, one for each state derivative.
Given we can calculate all state derivatives as a function of the states at one particular time instance, we can have a function mapping that outputs all the state dynamics for a particular state at collocation points given by a time vector ``\bar{t} = t_1, t_2 \ldots t_{m_i}``

$$
\pmb{f} = f_i(\pmb{x}(\bar{t}),\pmb{u}(\bar{t})) : \mathbb{R}^{(n + c) \times m_i} \rightarrow \mathbb{R}^{m_i}, \quad i = 1,2\ldots n
$$

Where ``n`` here is the number of both states and controls, and ``m_i`` is the number of collocation points for each state index ``i``.
The keen eye will note that for each individual function evaluation, the input array is assumed to have dimensions ``n \times m_i``, while in equation ``\ref{xState}`` and ``\ref{uControl}`` we observe that these arrays do not necessarily have a rectangular representation (rather they are more arrays of varying length vectors).
We resolve this by interpolating the values of ``x`` and ``u`` at some time ``t``.

Putting this all together we have
$$
\pmb{x}\left\{\begin{matrix}
\bar{x_1} =& [x_{11}, x_{12} \ldots x_{1m_1} ] \\
 \ldots & \\ 
\bar{x_n} =& [x_{n1}, x_{n2} \ldots x_{nm_n} ] 
\end{matrix}\right.
$$
$$
n = \text{number of states}, m_i = \text{states mesh sizes}, i = 1,2\ldots n
\medskip
$$

$$
\pmb{u}\left\{\begin{matrix}
\bar{u_1} =& [u_{11}, u_{12} \ldots u_{1m_1} ] \\
 \ldots & \\ 
\bar{u_c} =& [u_{c1}, u_{c2} \ldots u_{cm_c} ] 
\end{matrix}\right.
$$
$$
c = \text{number of controls}, m_i = \text{controls mesh sizes}, i = 1,2\ldots c
\medskip
$$
$$
\pmb{f}\left\{\begin{matrix}
\dot{\bar{x}}_1 =& f_1(\pmb{x}(t_1),\pmb{u}(t_1)\ldots\pmb{x}(t_{m_1}),\pmb{u}(t_{m_1})) \\
 \ldots & \\ 
\dot{\bar{x}}_n =& f_n(\pmb{x}(t_1),\pmb{u}(t_1)\ldots\pmb{x}(t_{m_n}),\pmb{u}(t_{m_n})) 
\end{matrix}\right.
$$
$$
n = \text{number of states}, m_i = \text{number of state collocation points}, i = 1,2 \ldots n
\medskip
$$

Now that we have our system dynamics functions, we need to transform them into a format that can be solved with an NLP solver.
This is the process of transcription and we do this by creating a set of equality constraints that enforce system dynamics at our chosen collocation points.
At these points we can verify that the system satisfies the laws of physics (if the problem is physical).
However, between collocation points we do not enforce such laws, and solutions must be interpolated, from which we derive a certain amount of error from approximation.
Additionally, oscillations can occur between collocation points if the system is significantly ill-defined.


This process generally involves us approximating the derivatives of the state vector at our collocation points, and in some way equating these with our dynamics function.
There are many of these approximations, but the simplest of these (and the one that probably illustrates the point best) is the euler method in equation ``\ref{euler}``.
Note here ``h_k`` is the timestep ``h_k = t_{k+1} - t_k``

$$
\frac{\partial \pmb{x}_{ik}}{\partial t} = \pmb{f}_{ik} \approx \frac{\pmb{x}_{ik+1} - \pmb{x}_{ik}}{h_k}
$$
$$
\begin{equation}
\label{euler}
\pmb{x}_{ik+1} - \pmb{x}_{ik} - h_k \pmb{f}_{ik} = 0
\end{equation}
$$

All other methods are extensions of this principle, but aim to have more accurate estimations of state derivatives at collocation points.
Take for example the trapizoidal method

$$
\begin{equation}
\label{trap}
\pmb{x}_{ik+1} - \pmb{x}_{ik} - \frac{h_k}{2} (\pmb{f}_{ik} + \pmb{f}_{ik+1}) = 0
\end{equation}
$$

Here we take an average of the system dynamics at the ``k`` and the ``k+1`` collocation point (the derivation comes from the trapizoidal integration approximation, hense trapizoidal method).

Equations ``\ref{euler}`` and ``\ref{trap}`` are formulations of the system dynamics as equality constraints which are in the form of equation ``\ref{gfunceq}`` and thus solvable by an NLP solver. 
Next we will look into formulating our path and boundary constraints for the NLP problem.
<!-- give oscillating figure for this too --> 
<!-- discuss the jacobian -->


### `j print(problemComponents[2])`
Almost all dynamic optimisation problems will require some form of constraint on our system.
Constraints can be categorised as either boundary constraints or path constraints.
Boundary constraints occur at the start and endpoints of the problem i.e. at ``t=t_1`` and ``t=t_F`` (as is consistent with Julia syntax we assume 1 is our initial value rather than 0).
Boundary constraints may either be fixed limits or a function of the boundary values.
In the case of fixed limits, we have
$$
t_1^L \leq t_1 \leq t_1^U
$$
$$
t_1^L \leq t_F \leq t_F^U
$$
$$
\pmb{x}_1^L \leq \pmb{x}(t_1) \leq \pmb{x}_1^U
$$
$$
\pmb{x}_F^L \leq \pmb{x}(t_F) \leq \pmb{x}_F^U
$$

which are all perturbations of equation ``\ref{xineq}``.
Examples of fixed limits would be wanting to finish at a particular location, or with no fuel left etc.

Additionally we may formulate constraints as a function of boundary values
$$
\pmb{b}(t_1,t_F,\pmb{x}(t_1),\pmb{x}(t_F)) \leq 0
$$
which again can be represented in our NLP solver by equation ``\ref{gfunc}``.
An example of a boundary constraint function would be a function ensuring that the final speed of a spacecraft matches that of a spacestation in orbit.

Path constrains follow an almost identical formulation but apply to the whole of the path through time and consider control input as well.
$$
\begin{equation}
\label{xpath}
\pmb{x}^L \leq \pmb{x}(t_k) \leq \pmb{x}^U
\end{equation}
$$
$$
\begin{equation}
\label{upath}
\pmb{u}^L \leq \pmb{u}(t_k) \leq \pmb{u}^U
\end{equation}
$$
$$
\begin{equation}
\label{bpath}
\pmb{h}(t_k,\pmb{x}(t_k),\pmb{u}(t_k)) \leq 0
\end{equation}
$$

Once again for the sake of completeness equations ``\ref{xpath}`` and ``\ref{upath}`` correspond to equation ``\ref{xineq}`` and equation ``\ref{bpath}`` to equation ``\ref{gfunc}`` in our NLP formulation.
Finally we will look at the objective function formulation.

### `j print(problemComponents[3])`

## Julia Packages


# Project Ethos
The main aims of the project are derived from lessons learnt in ICLOCS, and are as follows:
```julia; echo=false
aims = ["Code structure must be modular",
        "Code must be sufficiently verbose when handling errors",
        "Code must verify data before computation",
        "The final package must be user extensible and have the ability to support multiple solvers",
        "Location of mesh points for each state must be independent of other states",
        "The MorePolynomials package must interface well with the existing Polynomials package"];
```
1) `j print(aims[1])`
2) `j print(aims[2])`
3) `j print(aims[3])`

* JuDO 
4) `j print(aims[4])`
5) `j print(aims[5])`
    

* MorePolynomials
6) `j print(aims[6])`

## `j print(aims[1])`
It has been identified that the ICLOCS package has reached a feature saturation point, such that further expansion would require a large proportion of code to be rewritten.
One of the primary aims of this project is to write code which is sufficiently extensible by leveraging features in Julia such as types and multiple dispatch that allow for greater code separation. 
Examples of this can be found in section ``\ref{morepoly}``, where multiple dispatch and abstract typing allow us to utilise existing functions in the Polynomials.jl package while extending it to work with our own function definitions.
This would be far more difficult in a traditional OOP based language.

## `j print(aims[2])`
When describing the dynamic optimisation problem, the use of verbose error handling and user feedback is extremely useful in guiding the user to both a solvable and well constructed problem.
This was particular apparent in the formulation of problems in the ICLOCS package.
Often errors in the user defined problem (UDP) would result in error traces that lead deep into the core of the code, providing little help to the user who's only course of action would be to trace the flow of data through the sourcecode of ICLOCS.
The aim of this new package is to catch errors elegantly, and give the user contextual feedback.

## `j print(aims[3])`
Closely related to well implemented error handling is the verification of the data in the first place.
The phrase garbage in garbage out is relevant here.
If we ensure the quality of the UDP before any computation, we can ensure the speed and freedom from errors in the results.
The reverse is true, that if no verification takes place, the UDP could result in hard to debug errors embedded in the source code, which is not where we want them.
By leveraging Julia's explicit type system, we can remove potential conversion errors further down the line by internally specifying the types of the components of the UDP.
Further pre solve check can ensure the quality and compatibility of the UDP with internal solver interfaces.
This also has the added benefit of speeding up computation when the compiles is aware of the types at runtime.

## `j print(aims[4])`
This is particular important for the longevity of the project.
Bespoke programs could be created for each individual solver, but a more ideal solution would be to create a generic framework from which additional solvers can be plugged in.
This is highly dependent on the nature of each solver, and additional solver specific syntax may need to be included in the UDP (e.g. if the solver is not black box, additional derivatives may need to be provided unless numerically calculated).
However, this goal is more focused towards ease of future development, rather than the user interface.

## `j print(aims[5])`
By isolation of each state, we can vary the density of mesh points for each state.
As such, states which can be approximated by a smaller mesh size do not occupy unnecessary space in memory due to other states requiring a larger mesh size to achieve an accurate approximation.
This can be achieved by interpolating the state at collocation points when required.

## `j print(aims[6])`
As Polynomials.jl is a rapidly developing package, ensuring compatibility allows for easy integration of future features.
As Julia is an ever evolving language, by building off prexisting packages we can make the MorePolynomials.jl packages appealing for users already familiar with the framework, while reducing developer load on are part as Polynomials.jl is updated with Julia updates.
The disadvantage being we are then at the mercy of the Polynomials.jl package developers.
If they decided to change their framework entirely, our package may also need to change.
This is not necessarily an issue however as we can specify backwards compatibility.



# Results and Discussion

## User interface
### Error handling
## Benchmarking and performance gains
# Documentation
# Next steps
! BeginFig()

```julia; out_width="0.7\\textwidth";echo=false
img = load("figures/gargpretransformu.png")

```
! EndFig("a","b")
! BeginFig()

```julia; out_width="0.7\\textwidth";echo=false
img = load("figures/gargpretransformy.png")

```
! EndFig("a","b")
! BeginFig()

```julia; out_width="0.7\\textwidth";echo=false
img = load("figures/gargposttransformu.png")

```
! EndFig("a","b")
! BeginFig()

```julia; out_width="0.7\\textwidth";echo=false
img = load("figures/gargposttransformy.png")

```
! EndFig("a","b")

<!-- ipopt: https://coin-or.github.io/Ipopt/ --> 
<!-- ipopttut: Short tutorial Ipopt.pdf --> 
